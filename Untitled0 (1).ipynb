{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6IzH7bDyXxV9",
        "outputId": "24576a8b-3f8d-4f27-ff7e-7af1eeb8b9c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Bắt đầu QUY TRÌNH HOÀN CHỈNH trên T4 GPU ---\n",
            "\n",
            "[BƯỚC 1]: Tải dự án và cài đặt phụ thuộc...\n",
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 347415, done.\u001b[K\n",
            "remote: Counting objects: 100% (1437/1437), done.\u001b[K\n",
            "remote: Compressing objects: 100% (796/796), done.\u001b[K\n",
            "remote: Total 347415 (delta 994), reused 641 (delta 641), pack-reused 345978 (from 4)\u001b[K\n",
            "Receiving objects: 100% (347415/347415), 363.65 MiB | 20.92 MiB/s, done.\n",
            "Resolving deltas: 100% (264316/264316), done.\n",
            "Updating files: 100% (5289/5289), done.\n",
            "Đã chuyển sang thư mục: /content/transformers\n",
            "Obtaining file:///content/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting filelock (from transformers==4.57.0.dev0)\n",
            "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting huggingface-hub==1.0.0.rc2 (from transformers==4.57.0.dev0)\n",
            "  Downloading huggingface_hub-1.0.0rc2-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy>=1.17 (from transformers==4.57.0.dev0)\n",
            "  Downloading numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0 (from transformers==4.57.0.dev0)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyyaml>=5.1 (from transformers==4.57.0.dev0)\n",
            "  Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers==4.57.0.dev0)\n",
            "  Downloading regex-2025.9.18-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests (from transformers==4.57.0.dev0)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers==4.57.0.dev0)\n",
            "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers==4.57.0.dev0)\n",
            "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting tqdm>=4.27 (from transformers==4.57.0.dev0)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub==1.0.0.rc2->transformers==4.57.0.dev0)\n",
            "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from huggingface-hub==1.0.0.rc2->transformers==4.57.0.dev0)\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typer-slim (from huggingface-hub==1.0.0.rc2->transformers==4.57.0.dev0)\n",
            "  Downloading typer_slim-0.19.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub==1.0.0.rc2->transformers==4.57.0.dev0)\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub==1.0.0.rc2->transformers==4.57.0.dev0)\n",
            "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Collecting pytest>=7.2.0 (from transformers==4.57.0.dev0)\n",
            "  Downloading pytest-8.4.2-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting pytest-asyncio (from transformers==4.57.0.dev0)\n",
            "  Downloading pytest_asyncio-1.2.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting pytest-rich (from transformers==4.57.0.dev0)\n",
            "  Downloading pytest_rich-0.2.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting pytest-xdist (from transformers==4.57.0.dev0)\n",
            "  Downloading pytest_xdist-3.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting pytest-order (from transformers==4.57.0.dev0)\n",
            "  Downloading pytest_order-1.3.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting pytest-rerunfailures<16.0 (from transformers==4.57.0.dev0)\n",
            "  Downloading pytest_rerunfailures-15.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting timeout-decorator (from transformers==4.57.0.dev0)\n",
            "  Downloading timeout-decorator-0.5.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting parameterized>=0.9 (from transformers==4.57.0.dev0)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting psutil (from transformers==4.57.0.dev0)\n",
            "  Downloading psutil-7.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
            "Collecting datasets>=2.15.0 (from transformers==4.57.0.dev0)\n",
            "  Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting dill<0.3.5 (from transformers==4.57.0.dev0)\n",
            "  Downloading dill-0.3.4-py2.py3-none-any.whl.metadata (9.6 kB)\n",
            "Collecting evaluate>=0.2.0 (from transformers==4.57.0.dev0)\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pytest-timeout (from transformers==4.57.0.dev0)\n",
            "  Downloading pytest_timeout-2.4.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting ruff==0.13.1 (from transformers==4.57.0.dev0)\n",
            "  Downloading ruff-0.13.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting rouge-score!=0.0.7,!=0.0.8,!=0.1,!=0.1.1 (from transformers==4.57.0.dev0)\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nltk<=3.8.1 (from transformers==4.57.0.dev0)\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting GitPython<3.1.19 (from transformers==4.57.0.dev0)\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting sacremoses (from transformers==4.57.0.dev0)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting rjieba (from transformers==4.57.0.dev0)\n",
            "  Downloading rjieba-0.1.13-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting beautifulsoup4 (from transformers==4.57.0.dev0)\n",
            "  Downloading beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting tensorboard (from transformers==4.57.0.dev0)\n",
            "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting pydantic>=2 (from transformers==4.57.0.dev0)\n",
            "  Downloading pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.4/68.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92,>=0.1.91 (from transformers==4.57.0.dev0)\n",
            "  Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting sacrebleu<2.0.0,>=1.4.12 (from transformers==4.57.0.dev0)\n",
            "  Downloading sacrebleu-1.5.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting libcst (from transformers==4.57.0.dev0)\n",
            "  Downloading libcst-1.8.5-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (15 kB)\n",
            "Collecting faiss-cpu (from transformers==4.57.0.dev0)\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting cookiecutter==1.7.3 (from transformers==4.57.0.dev0)\n",
            "  Downloading cookiecutter-1.7.3-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mistral-common>=1.6.3 (from mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Downloading mistral_common-1.8.5-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting openai>=1.98.0 (from transformers==4.57.0.dev0)\n",
            "  Downloading openai-2.0.1-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting uvicorn (from transformers==4.57.0.dev0)\n",
            "  Downloading uvicorn-0.37.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting fastapi (from transformers==4.57.0.dev0)\n",
            "  Downloading fastapi-0.118.0-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting starlette (from transformers==4.57.0.dev0)\n",
            "  Downloading starlette-0.48.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting torch>=2.2 (from transformers==4.57.0.dev0)\n",
            "  Downloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting accelerate>=0.26.0 (from transformers==4.57.0.dev0)\n",
            "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting binaryornot>=0.4.4 (from cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading binaryornot-0.4.4-py2.py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting Jinja2<4.0.0,>=2.7 (from cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting click>=7.0 (from cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting poyo>=0.5.0 (from cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading poyo-0.5.0-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting jinja2-time>=0.2.0 (from cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading jinja2_time-0.2.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-slugify>=4.0.0 (from cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting six>=1.10 (from cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting pyarrow>=21.0.0 (from datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting pandas (from datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython<3.1.19->transformers==4.57.0.dev0)\n",
            "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting jsonschema>=4.21.1 (from mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting tiktoken>=0.7.0 (from mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Downloading tiktoken-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting pillow>=10.3.0 (from mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Downloading pydantic_extra_types-2.10.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting opencv-python-headless>=4.0.0 (from mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "Collecting joblib (from nltk<=3.8.1->transformers==4.57.0.dev0)\n",
            "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting anyio<5,>=3.5.0 (from openai>=1.98.0->transformers==4.57.0.dev0)\n",
            "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai>=1.98.0->transformers==4.57.0.dev0)\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.98.0->transformers==4.57.0.dev0)\n",
            "  Downloading jiter-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting sniffio (from openai>=1.98.0->transformers==4.57.0.dev0)\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic>=2->transformers==4.57.0.dev0)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic>=2->transformers==4.57.0.dev0)\n",
            "  Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic>=2->transformers==4.57.0.dev0)\n",
            "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting iniconfig>=1 (from pytest>=7.2.0->transformers==4.57.0.dev0)\n",
            "  Downloading iniconfig-2.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting pluggy<2,>=1.5 (from pytest>=7.2.0->transformers==4.57.0.dev0)\n",
            "  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting pygments>=2.7.2 (from pytest>=7.2.0->transformers==4.57.0.dev0)\n",
            "  Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->transformers==4.57.0.dev0)\n",
            "  Downloading charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->transformers==4.57.0.dev0)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.57.0.dev0)\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers==4.57.0.dev0)\n",
            "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting absl-py (from rouge-score!=0.0.7,!=0.0.8,!=0.1,!=0.1.1->transformers==4.57.0.dev0)\n",
            "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting portalocker==2.0.0 (from sacrebleu<2.0.0,>=1.4.12->transformers==4.57.0.dev0)\n",
            "  Downloading portalocker-2.0.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting setuptools (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sympy>=1.13.3 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.4.0 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4->transformers==4.57.0.dev0)\n",
            "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting attrs (from pytest-rich->transformers==4.57.0.dev0)\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting rich (from pytest-rich->transformers==4.57.0.dev0)\n",
            "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting execnet>=2.1 (from pytest-xdist->transformers==4.57.0.dev0)\n",
            "  Downloading execnet-2.1.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard->transformers==4.57.0.dev0)\n",
            "  Downloading grpcio-1.75.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard->transformers==4.57.0.dev0)\n",
            "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard->transformers==4.57.0.dev0)\n",
            "  Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->transformers==4.57.0.dev0)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard->transformers==4.57.0.dev0)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting h11>=0.8 (from uvicorn->transformers==4.57.0.dev0)\n",
            "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting chardet>=3.0.2 (from binaryornot>=0.4.4->cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython<3.1.19->transformers==4.57.0.dev0)\n",
            "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->huggingface-hub==1.0.0.rc2->transformers==4.57.0.dev0)\n",
            "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting MarkupSafe>=2.0 (from Jinja2<4.0.0,>=2.7->cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting arrow (from jinja2-time>=0.2.0->cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.21.1->mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=4.21.1->mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=4.21.1->mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Downloading rpds_py-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading multiprocess-0.70.13-py310-none-any.whl.metadata (6.8 kB)\n",
            "  Downloading multiprocess-0.70.12.2-py39-none-any.whl.metadata (6.9 kB)\n",
            "Collecting numpy>=1.17 (from transformers==4.57.0.dev0)\n",
            "  Downloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting text-unidecode>=1.3 (from python-slugify>=4.0.0->cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->pytest-rich->transformers==4.57.0.dev0)\n",
            "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->pytest-rich->transformers==4.57.0.dev0)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow->jinja2-time>=0.2.0->cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading types_python_dateutil-2.9.0.20250822-py3-none-any.whl.metadata (1.8 kB)\n",
            "Downloading huggingface_hub-1.0.0rc2-py3-none-any.whl (528 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.7/528.7 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cookiecutter-1.7.3-py2.py3-none-any.whl (34 kB)\n",
            "Downloading ruff-0.13.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.9/374.9 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-4.1.1-py3-none-any.whl (503 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.6/503.6 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.1/170.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistral_common-1.8.5-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-2.0.1-py3-none-any.whl (956 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m956.3/956.3 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.9/444.9 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest-8.4.2-py3-none-any.whl (365 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.8/365.8 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_rerunfailures-15.1-py3-none-any.whl (13 kB)\n",
            "Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2025.9.18-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (802 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.0/802.0 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.8/485.8 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (887.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.9/887.9 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.4/106.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.118.0-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.7/97.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.48.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Downloading libcst-1.8.5-cp312-cp312-manylinux_2_28_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (291 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.2/291.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_asyncio-1.2.0-py3-none-any.whl (15 kB)\n",
            "Downloading pytest_order-1.3.0-py3-none-any.whl (14 kB)\n",
            "Downloading pytest_rich-0.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading pytest_timeout-2.4.0-py3-none-any.whl (14 kB)\n",
            "Downloading pytest_xdist-3.8.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rjieba-0.1.13-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.37.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.0/68.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading binaryornot-0.4.4-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.2/161.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.8/151.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.3.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading execnet-2.1.1-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.75.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iniconfig-2.1.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2_time-0.2.0-py2.py3-none-any.whl (6.4 kB)\n",
            "Downloading jiter-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.9/347.9 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown-3.9-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.12.2-py39-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
            "Downloading poyo-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_extra_types-2.10.5-py3-none-any.whl (38 kB)\n",
            "Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
            "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.4/308.4 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer_slim-0.19.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
            "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Downloading rpds_py-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
            "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.8/241.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.1/256.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.4/224.4 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20250822-py3-none-any.whl (17 kB)\n",
            "Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.6/355.6 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers, rouge-score, timeout-decorator\n",
            "  Building editable for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.57.0.dev0-0.editable-py3-none-any.whl size=14982 sha256=f8763515d49f315f77ab0ec60fe263ba794b17d7613c4369793b0bfc4167bb45\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-94d_5rq0/wheels/5d/95/aa/7bf76982b5186f967ea8b0d48a21290fa6c5c65b1e12ae5460\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=afc10d026f02b732ec506c17f8093b6e522d7ebbfb03ad2a02faf9664a0a1586\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
            "  Building wheel for timeout-decorator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for timeout-decorator: filename=timeout_decorator-0.5.0-py3-none-any.whl size=5006 sha256=41628945013674732b9187742969e4e3b430ffd9fd490568554531c32e13b090\n",
            "  Stored in directory: /root/.cache/pip/wheels/4d/6a/e3/c4f2cdd67648203ccf069daa31c3935a5c74ec04cccbac9411\n",
            "Successfully built transformers rouge-score timeout-decorator\n",
            "Installing collected packages: timeout-decorator, text-unidecode, rjieba, pytz, portalocker, nvidia-cusparselt-cu12, mpmath, xxhash, urllib3, tzdata, typing-extensions, types-python-dateutil, tqdm, tensorboard-data-server, sympy, soupsieve, sniffio, smmap, six, setuptools, sentencepiece, safetensors, sacrebleu, ruff, rpds-py, regex, pyyaml, python-slugify, pygments, pycountry, pyarrow, psutil, protobuf, propcache, poyo, pluggy, pillow, parameterized, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multidict, mdurl, MarkupSafe, markdown, joblib, jiter, iniconfig, idna, hf-xet, h11, fsspec, frozenlist, filelock, execnet, distro, dill, click, charset_normalizer, chardet, certifi, attrs, annotated-types, aiohappyeyeballs, absl-py, yarl, werkzeug, uvicorn, typing-inspection, typer-slim, triton, sacremoses, requests, referencing, python-dateutil, pytest, pydantic-core, opencv-python-headless, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nltk, multiprocess, markdown-it-py, libcst, Jinja2, httpcore, grpcio, gitdb, faiss-cpu, binaryornot, beautifulsoup4, anyio, aiosignal, tiktoken, tensorboard, starlette, rouge-score, rich, pytest-xdist, pytest-timeout, pytest-rerunfailures, pytest-order, pytest-asyncio, pydantic, pandas, nvidia-cusolver-cu12, jsonschema-specifications, httpx, GitPython, arrow, aiohttp, torch, pytest-rich, pydantic-extra-types, openai, jsonschema, jinja2-time, huggingface-hub, fastapi, tokenizers, datasets, cookiecutter, accelerate, transformers, mistral-common, evaluate\n",
            "  Attempting uninstall: text-unidecode\n",
            "    Found existing installation: text-unidecode 1.3\n",
            "    Uninstalling text-unidecode-1.3:\n",
            "      Successfully uninstalled text-unidecode-1.3\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: xxhash\n",
            "    Found existing installation: xxhash 3.5.0\n",
            "    Uninstalling xxhash-3.5.0:\n",
            "      Successfully uninstalled xxhash-3.5.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: types-python-dateutil\n",
            "    Found existing installation: types-python-dateutil 2.9.0.20250822\n",
            "    Uninstalling types-python-dateutil-2.9.0.20250822:\n",
            "      Successfully uninstalled types-python-dateutil-2.9.0.20250822\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "  Attempting uninstall: soupsieve\n",
            "    Found existing installation: soupsieve 2.8\n",
            "    Uninstalling soupsieve-2.8:\n",
            "      Successfully uninstalled soupsieve-2.8\n",
            "  Attempting uninstall: sniffio\n",
            "    Found existing installation: sniffio 1.3.1\n",
            "    Uninstalling sniffio-1.3.1:\n",
            "      Successfully uninstalled sniffio-1.3.1\n",
            "  Attempting uninstall: smmap\n",
            "    Found existing installation: smmap 5.0.2\n",
            "    Uninstalling smmap-5.0.2:\n",
            "      Successfully uninstalled smmap-5.0.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.2.1\n",
            "    Uninstalling sentencepiece-0.2.1:\n",
            "      Successfully uninstalled sentencepiece-0.2.1\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.6.2\n",
            "    Uninstalling safetensors-0.6.2:\n",
            "      Successfully uninstalled safetensors-0.6.2\n",
            "  Attempting uninstall: ruff\n",
            "    Found existing installation: ruff 0.13.0\n",
            "    Uninstalling ruff-0.13.0:\n",
            "      Successfully uninstalled ruff-0.13.0\n",
            "  Attempting uninstall: rpds-py\n",
            "    Found existing installation: rpds-py 0.27.1\n",
            "    Uninstalling rpds-py-0.27.1:\n",
            "      Successfully uninstalled rpds-py-0.27.1\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: python-slugify\n",
            "    Found existing installation: python-slugify 8.0.4\n",
            "    Uninstalling python-slugify-8.0.4:\n",
            "      Successfully uninstalled python-slugify-8.0.4\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.19.2\n",
            "    Uninstalling Pygments-2.19.2:\n",
            "      Successfully uninstalled Pygments-2.19.2\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: propcache\n",
            "    Found existing installation: propcache 0.3.2\n",
            "    Uninstalling propcache-0.3.2:\n",
            "      Successfully uninstalled propcache-0.3.2\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 1.6.0\n",
            "    Uninstalling pluggy-1.6.0:\n",
            "      Successfully uninstalled pluggy-1.6.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.5\n",
            "    Uninstalling networkx-3.5:\n",
            "      Successfully uninstalled networkx-3.5\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.6.4\n",
            "    Uninstalling multidict-6.6.4:\n",
            "      Successfully uninstalled multidict-6.6.4\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.9\n",
            "    Uninstalling Markdown-3.9:\n",
            "      Successfully uninstalled Markdown-3.9\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.5.2\n",
            "    Uninstalling joblib-1.5.2:\n",
            "      Successfully uninstalled joblib-1.5.2\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.11.0\n",
            "    Uninstalling jiter-0.11.0:\n",
            "      Successfully uninstalled jiter-0.11.0\n",
            "  Attempting uninstall: iniconfig\n",
            "    Found existing installation: iniconfig 2.1.0\n",
            "    Uninstalling iniconfig-2.1.0:\n",
            "      Successfully uninstalled iniconfig-2.1.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: hf-xet\n",
            "    Found existing installation: hf-xet 1.1.10\n",
            "    Uninstalling hf-xet-1.1.10:\n",
            "      Successfully uninstalled hf-xet-1.1.10\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.16.0\n",
            "    Uninstalling h11-0.16.0:\n",
            "      Successfully uninstalled h11-0.16.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: frozenlist\n",
            "    Found existing installation: frozenlist 1.7.0\n",
            "    Uninstalling frozenlist-1.7.0:\n",
            "      Successfully uninstalled frozenlist-1.7.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.19.1\n",
            "    Uninstalling filelock-3.19.1:\n",
            "      Successfully uninstalled filelock-3.19.1\n",
            "  Attempting uninstall: distro\n",
            "    Found existing installation: distro 1.9.0\n",
            "    Uninstalling distro-1.9.0:\n",
            "      Successfully uninstalled distro-1.9.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.8\n",
            "    Uninstalling dill-0.3.8:\n",
            "      Successfully uninstalled dill-0.3.8\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.2.1\n",
            "    Uninstalling click-8.2.1:\n",
            "      Successfully uninstalled click-8.2.1\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.3\n",
            "    Uninstalling charset-normalizer-3.4.3:\n",
            "      Successfully uninstalled charset-normalizer-3.4.3\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.8.3\n",
            "    Uninstalling certifi-2025.8.3:\n",
            "      Successfully uninstalled certifi-2025.8.3\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.3.0\n",
            "    Uninstalling attrs-25.3.0:\n",
            "      Successfully uninstalled attrs-25.3.0\n",
            "  Attempting uninstall: annotated-types\n",
            "    Found existing installation: annotated-types 0.7.0\n",
            "    Uninstalling annotated-types-0.7.0:\n",
            "      Successfully uninstalled annotated-types-0.7.0\n",
            "  Attempting uninstall: aiohappyeyeballs\n",
            "    Found existing installation: aiohappyeyeballs 2.6.1\n",
            "    Uninstalling aiohappyeyeballs-2.6.1:\n",
            "      Successfully uninstalled aiohappyeyeballs-2.6.1\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.20.1\n",
            "    Uninstalling yarl-1.20.1:\n",
            "      Successfully uninstalled yarl-1.20.1\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: uvicorn\n",
            "    Found existing installation: uvicorn 0.35.0\n",
            "    Uninstalling uvicorn-0.35.0:\n",
            "      Successfully uninstalled uvicorn-0.35.0\n",
            "  Attempting uninstall: typing-inspection\n",
            "    Found existing installation: typing-inspection 0.4.1\n",
            "    Uninstalling typing-inspection-0.4.1:\n",
            "      Successfully uninstalled typing-inspection-0.4.1\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: referencing\n",
            "    Found existing installation: referencing 0.36.2\n",
            "    Uninstalling referencing-0.36.2:\n",
            "      Successfully uninstalled referencing-0.36.2\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 8.4.2\n",
            "    Uninstalling pytest-8.4.2:\n",
            "      Successfully uninstalled pytest-8.4.2\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.9.1\n",
            "    Uninstalling nltk-3.9.1:\n",
            "      Successfully uninstalled nltk-3.9.1\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.16\n",
            "    Uninstalling multiprocess-0.70.16:\n",
            "      Successfully uninstalled multiprocess-0.70.16\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 4.0.0\n",
            "    Uninstalling markdown-it-py-4.0.0:\n",
            "      Successfully uninstalled markdown-it-py-4.0.0\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.9\n",
            "    Uninstalling httpcore-1.0.9:\n",
            "      Successfully uninstalled httpcore-1.0.9\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.75.0\n",
            "    Uninstalling grpcio-1.75.0:\n",
            "      Successfully uninstalled grpcio-1.75.0\n",
            "  Attempting uninstall: gitdb\n",
            "    Found existing installation: gitdb 4.0.12\n",
            "    Uninstalling gitdb-4.0.12:\n",
            "      Successfully uninstalled gitdb-4.0.12\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.13.5\n",
            "    Uninstalling beautifulsoup4-4.13.5:\n",
            "      Successfully uninstalled beautifulsoup4-4.13.5\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 4.10.0\n",
            "    Uninstalling anyio-4.10.0:\n",
            "      Successfully uninstalled anyio-4.10.0\n",
            "  Attempting uninstall: aiosignal\n",
            "    Found existing installation: aiosignal 1.4.0\n",
            "    Uninstalling aiosignal-1.4.0:\n",
            "      Successfully uninstalled aiosignal-1.4.0\n",
            "  Attempting uninstall: tiktoken\n",
            "    Found existing installation: tiktoken 0.11.0\n",
            "    Uninstalling tiktoken-0.11.0:\n",
            "      Successfully uninstalled tiktoken-0.11.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.19.0\n",
            "    Uninstalling tensorboard-2.19.0:\n",
            "      Successfully uninstalled tensorboard-2.19.0\n",
            "  Attempting uninstall: starlette\n",
            "    Found existing installation: starlette 0.48.0\n",
            "    Uninstalling starlette-0.48.0:\n",
            "      Successfully uninstalled starlette-0.48.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.9\n",
            "    Uninstalling pydantic-2.11.9:\n",
            "      Successfully uninstalled pydantic-2.11.9\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: jsonschema-specifications\n",
            "    Found existing installation: jsonschema-specifications 2025.9.1\n",
            "    Uninstalling jsonschema-specifications-2025.9.1:\n",
            "      Successfully uninstalled jsonschema-specifications-2025.9.1\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: GitPython\n",
            "    Found existing installation: GitPython 3.1.45\n",
            "    Uninstalling GitPython-3.1.45:\n",
            "      Successfully uninstalled GitPython-3.1.45\n",
            "  Attempting uninstall: arrow\n",
            "    Found existing installation: arrow 1.3.0\n",
            "    Uninstalling arrow-1.3.0:\n",
            "      Successfully uninstalled arrow-1.3.0\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.12.15\n",
            "    Uninstalling aiohttp-3.12.15:\n",
            "      Successfully uninstalled aiohttp-3.12.15\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.108.0\n",
            "    Uninstalling openai-1.108.0:\n",
            "      Successfully uninstalled openai-1.108.0\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.25.1\n",
            "    Uninstalling jsonschema-4.25.1:\n",
            "      Successfully uninstalled jsonschema-4.25.1\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.35.0\n",
            "    Uninstalling huggingface-hub-0.35.0:\n",
            "      Successfully uninstalled huggingface-hub-0.35.0\n",
            "  Attempting uninstall: fastapi\n",
            "    Found existing installation: fastapi 0.116.2\n",
            "    Uninstalling fastapi-0.116.2:\n",
            "      Successfully uninstalled fastapi-0.116.2\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.0\n",
            "    Uninstalling tokenizers-0.22.0:\n",
            "      Successfully uninstalled tokenizers-0.22.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.10.1\n",
            "    Uninstalling accelerate-1.10.1:\n",
            "      Successfully uninstalled accelerate-1.10.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.56.1\n",
            "    Uninstalling transformers-4.56.1:\n",
            "      Successfully uninstalled transformers-4.56.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\n",
            "bigframes 2.21.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\n",
            "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
            "textblob 0.19.0 requires nltk>=3.9, but you have nltk 3.8.1 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.32.1 which is incompatible.\n",
            "tensorflow 2.19.0 requires tensorboard~=2.19.0, but you have tensorboard 2.20.0 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.32.1 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.32.1 which is incompatible.\n",
            "gradio 5.46.0 requires huggingface-hub<1.0,>=0.33.5, but you have huggingface-hub 1.0.0rc2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.18 Jinja2-3.1.6 MarkupSafe-3.0.3 absl-py-2.3.1 accelerate-1.10.1 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 annotated-types-0.7.0 anyio-4.11.0 arrow-1.3.0 attrs-25.3.0 beautifulsoup4-4.14.2 binaryornot-0.4.4 certifi-2025.8.3 chardet-5.2.0 charset_normalizer-3.4.3 click-8.3.0 cookiecutter-1.7.3 datasets-4.1.1 dill-0.3.4 distro-1.9.0 evaluate-0.4.6 execnet-2.1.1 faiss-cpu-1.12.0 fastapi-0.118.0 filelock-3.19.1 frozenlist-1.7.0 fsspec-2025.9.0 gitdb-4.0.12 grpcio-1.75.1 h11-0.16.0 hf-xet-1.1.10 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-1.0.0rc2 idna-3.10 iniconfig-2.1.0 jinja2-time-0.2.0 jiter-0.11.0 joblib-1.5.2 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 libcst-1.8.5 markdown-3.9 markdown-it-py-4.0.0 mdurl-0.1.2 mistral-common-1.8.5 mpmath-1.3.0 multidict-6.6.4 multiprocess-0.70.12.2 networkx-3.5 nltk-3.8.1 numpy-2.2.6 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 openai-2.0.1 opencv-python-headless-4.12.0.88 packaging-25.0 pandas-2.3.3 parameterized-0.9.0 pillow-11.3.0 pluggy-1.6.0 portalocker-2.0.0 poyo-0.5.0 propcache-0.3.2 protobuf-6.32.1 psutil-7.1.0 pyarrow-21.0.0 pycountry-24.6.1 pydantic-2.11.9 pydantic-core-2.33.2 pydantic-extra-types-2.10.5 pygments-2.19.2 pytest-8.4.2 pytest-asyncio-1.2.0 pytest-order-1.3.0 pytest-rerunfailures-15.1 pytest-rich-0.2.0 pytest-timeout-2.4.0 pytest-xdist-3.8.0 python-dateutil-2.9.0.post0 python-slugify-8.0.4 pytz-2025.2 pyyaml-6.0.3 referencing-0.36.2 regex-2025.9.18 requests-2.32.5 rich-14.1.0 rjieba-0.1.13 rouge-score-0.1.2 rpds-py-0.27.1 ruff-0.13.1 sacrebleu-1.5.1 sacremoses-0.1.1 safetensors-0.6.2 sentencepiece-0.2.1 setuptools-80.9.0 six-1.17.0 smmap-5.0.2 sniffio-1.3.1 soupsieve-2.8 starlette-0.48.0 sympy-1.14.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 text-unidecode-1.3 tiktoken-0.11.0 timeout-decorator-0.5.0 tokenizers-0.22.1 torch-2.8.0 tqdm-4.67.1 transformers-4.57.0.dev0 triton-3.4.0 typer-slim-0.19.2 types-python-dateutil-2.9.0.20250822 typing-extensions-4.15.0 typing-inspection-0.4.2 tzdata-2025.2 urllib3-2.5.0 uvicorn-0.37.0 werkzeug-3.1.3 xxhash-3.5.0 yarl-1.20.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "certifi",
                  "dateutil",
                  "google",
                  "numpy",
                  "packaging",
                  "psutil",
                  "six"
                ]
              },
              "id": "352239e2d85b432e9515dcfb4a3105d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BƯỚC 1 HOÀN TẤT]\n",
            "\n",
            "[BƯỚC 2]: Bắt đầu chạy mô phỏng ViT trên CIFAR-10 (3 epochs)...\n",
            "--- Nếu xuất hiện 'wandb: Enter your choice:', hãy gõ 3 và nhấn Enter ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/transformers/examples/pytorch/image-classification/run_image_classification.py\", line 33, in <module>\n",
            "    import evaluate\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/evaluate/__init__.py\", line 29, in <module>\n",
            "    from .evaluation_suite import EvaluationSuite\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/evaluate/evaluation_suite/__init__.py\", line 10, in <module>\n",
            "    from ..evaluator import evaluator\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/evaluate/evaluator/__init__.py\", line 17, in <module>\n",
            "    from transformers.pipelines import SUPPORTED_TASKS as SUPPORTED_PIPELINE_TASKS\n",
            "  File \"/content/transformers/src/transformers/pipelines/__init__.py\", line 26, in <module>\n",
            "    from ..image_processing_utils import BaseImageProcessor\n",
            "  File \"/content/transformers/src/transformers/image_processing_utils.py\", line 21, in <module>\n",
            "    from .image_processing_base import BatchFeature, ImageProcessingMixin\n",
            "  File \"/content/transformers/src/transformers/image_processing_base.py\", line 26, in <module>\n",
            "    from .image_utils import is_valid_image, load_image\n",
            "  File \"/content/transformers/src/transformers/image_utils.py\", line 54, in <module>\n",
            "    from torchvision.transforms import InterpolationMode\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/__init__.py\", line 10, in <module>\n",
            "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  # usort:skip\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
            "    from .convnext import *\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py\", line 9, in <module>\n",
            "    from ..ops.misc import Conv2dNormActivation, Permute\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/ops/__init__.py\", line 23, in <module>\n",
            "    from .poolers import MultiScaleRoIAlign\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/ops/poolers.py\", line 10, in <module>\n",
            "    from .roi_align import roi_align\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/ops/roi_align.py\", line 7, in <module>\n",
            "    from torch._dynamo.utils import is_compile_supported\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/__init__.py\", line 13, in <module>\n",
            "    from . import config, convert_frame, eval_frame, resume_execution\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/convert_frame.py\", line 53, in <module>\n",
            "    from torch._dynamo.symbolic_convert import TensorifyState\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/symbolic_convert.py\", line 52, in <module>\n",
            "    from torch._dynamo.exc import TensorifyScalarRestartAnalysis\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/exc.py\", line 41, in <module>\n",
            "    from .utils import counters\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/utils.py\", line 69, in <module>\n",
            "    import torch.fx.experimental.symbolic_shapes\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 3, in <module>\n",
            "    import sympy\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sympy/__init__.py\", line 77, in <module>\n",
            "    from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sympy/polys/__init__.py\", line 124, in <module>\n",
            "    from .partfrac import apart, apart_list, assemble_partfrac_list\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sympy/polys/partfrac.py\", line 13, in <module>\n",
            "    @xthreaded\n",
            "     ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sympy/utilities/decorator.py\", line 82, in xthreaded\n",
            "^C\n",
            "\n",
            "[BƯỚC 2 HOÀN TẤT]\n",
            "\n",
            "[BƯỚC 3]: Đọc và hiển thị kết quả cuối cùng...\n",
            "Lỗi: Không tìm thấy tệp 'vit_cifar10_output/eval_results.json'. Quá trình huấn luyện không hoàn tất.\n",
            "\n",
            "--- QUY TRÌNH HOÀN TẤT ---\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import sys\n",
        "\n",
        "print(\"--- Bắt đầu QUY TRÌNH HOÀN CHỈNH trên T4 GPU ---\")\n",
        "\n",
        "# --- 1. Tải Code & Cài đặt Thư viện ---\n",
        "print(\"\\n[BƯỚC 1]: Tải dự án và cài đặt phụ thuộc...\")\n",
        "if os.path.exists(\"transformers\"):\n",
        "    # Xóa thư mục cũ để tránh lỗi \"already exists\"\n",
        "    !rm -rf transformers\n",
        "!git clone https://github.com/huggingface/transformers.git\n",
        "os.chdir(\"transformers\")\n",
        "print(f\"Đã chuyển sang thư mục: {os.getcwd()}\")\n",
        "# Cài đặt thư viện: dùng --upgrade --force-reinstall để giải quyết triệt để các xung đột\n",
        "!pip install -e \".[testing]\" --upgrade --force-reinstall\n",
        "print(\"[BƯỚC 1 HOÀN TẤT]\")\n",
        "\n",
        "# --- 2. Chạy Mô phỏng Vision Transformer (ViT) ---\n",
        "print(\"\\n[BƯỚC 2]: Bắt đầu chạy mô phỏng ViT trên CIFAR-10 (3 epochs)...\")\n",
        "print(\"--- Nếu xuất hiện 'wandb: Enter your choice:', hãy gõ 3 và nhấn Enter ---\")\n",
        "\n",
        "# Lệnh chạy script huấn luyện: sử dụng --image_column_name \"img\" và đường dẫn chính xác\n",
        "!python examples/pytorch/image-classification/run_image_classification.py \\\n",
        "    --model_name_or_path \"google/vit-base-patch16-224-in21k\" \\\n",
        "    --dataset_name \"cifar10\" \\\n",
        "    --output_dir \"../vit_cifar10_output\" \\\n",
        "    --remove_unused_columns False \\\n",
        "    --do_train --do_eval \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 3 \\\n",
        "    --per_device_train_batch_size 16 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --image_column_name \"img\"\n",
        "\n",
        "print(\"\\n[BƯỚC 2 HOÀN TẤT]\")\n",
        "# Quay lại thư mục gốc để thu thập kết quả\n",
        "os.chdir(\"../\")\n",
        "\n",
        "# --- 3. Thu thập và Hiển thị Kết quả Cuối cùng ---\n",
        "print(\"\\n[BƯỚC 3]: Đọc và hiển thị kết quả cuối cùng...\")\n",
        "output_dir = \"vit_cifar10_output\"\n",
        "eval_results_path = os.path.join(output_dir, \"eval_results.json\")\n",
        "\n",
        "try:\n",
        "    with open(eval_results_path, 'r') as f:\n",
        "        results = json.load(f)\n",
        "\n",
        "    print(\"\\n--- KẾT QUẢ ĐÁNH GIÁ CUỐI CÙNG CỦA MÔ PHỎNG (ViT) ---\")\n",
        "    for key, value in results.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "    print(\"\\nFile kết quả đã được lưu tại thư mục 'vit_cifar10_output'.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Lỗi: Không tìm thấy tệp '{eval_results_path}'. Quá trình huấn luyện không hoàn tất.\")\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"Lỗi: Không thể đọc tệp JSON. File có thể bị hỏng.\")\n",
        "\n",
        "print(\"\\n--- QUY TRÌNH HOÀN TẤT ---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Đảm bảo bạn đang ở trong thư mục 'transformers'\n",
        "import os\n",
        "try:\n",
        "    os.chdir(\"transformers\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Vui lòng chạy lại BƯỚC 1 và BƯỚC 2 (code gộp) trước.\")\n",
        "\n",
        "print(\"--- Bắt đầu chạy lại mô phỏng Vision Transformer (ViT) ---\")\n",
        "print(\"--- Vui lòng chờ cho đến khi quá trình này hoàn tất 100% (sau Epoch 3/3) ---\")\n",
        "\n",
        "# Lệnh chạy script huấn luyện\n",
        "!python examples/pytorch/image-classification/run_image_classification.py \\\n",
        "    --model_name_or_path \"google/vit-base-patch16-224-in21k\" \\\n",
        "    --dataset_name \"cifar10\" \\\n",
        "    --output_dir \"../vit_cifar10_output\" \\\n",
        "    --remove_unused_columns False \\\n",
        "    --do_train --do_eval \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 3 \\\n",
        "    --per_device_train_batch_size 16 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --image_column_name \"img\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uw9Zy3JpZ35T",
        "outputId": "4a313914-5d05-4f8c-9406-709fd7bf4fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Bắt đầu chạy lại mô phỏng Vision Transformer (ViT) ---\n",
            "--- Vui lòng chờ cho đến khi quá trình này hoàn tất 100% (sau Epoch 3/3) ---\n",
            "WARNING:__main__:Process rank: 0, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
            "INFO:__main__:Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=0,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=True,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=IntervalStrategy.NO,\n",
            "eval_use_gather_object=False,\n",
            "fp16=False,\n",
            "fp16_full_eval=False,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=None,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_num_input_tokens_seen=no,\n",
            "include_tokens_per_second=None,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=../vit_cifar10_output/runs/Oct02_00-52-14_681e9053e88f,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "num_train_epochs=3.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH_FUSED,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=../vit_cifar10_output,\n",
            "overwrite_output_dir=True,\n",
            "parallelism_config=None,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=16,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=False,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=None,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_liger_kernel=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "README.md: 5.16kB [00:00, 10.4MB/s]\n",
            "plain_text/train-00000-of-00001.parquet: 100% 120M/120M [00:01<00:00, 65.8MB/s]\n",
            "plain_text/test-00000-of-00001.parquet: 100% 23.9M/23.9M [00:00<00:00, 37.1MB/s]\n",
            "Generating train split: 100% 50000/50000 [00:00<00:00, 98651.39 examples/s] \n",
            "Generating test split: 100% 10000/10000 [00:00<00:00, 120771.34 examples/s]\n",
            "Downloading builder script: 4.20kB [00:00, 7.48MB/s]\n",
            "config.json: 100% 502/502 [00:00<00:00, 1.92MB/s]\n",
            "[INFO|configuration_utils.py:759] 2025-10-02 00:52:19,448 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/b4569560a39a0f1af58e3ddaf17facf20ab919b0/config.json\n",
            "[INFO|configuration_utils.py:833] 2025-10-02 00:52:19,449 >> Model config ViTConfig {\n",
            "  \"architectures\": [\n",
            "    \"ViTModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"encoder_stride\": 16,\n",
            "  \"finetuning_task\": \"image-classification\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"airplane\",\n",
            "    \"1\": \"automobile\",\n",
            "    \"2\": \"bird\",\n",
            "    \"3\": \"cat\",\n",
            "    \"4\": \"deer\",\n",
            "    \"5\": \"dog\",\n",
            "    \"6\": \"frog\",\n",
            "    \"7\": \"horse\",\n",
            "    \"8\": \"ship\",\n",
            "    \"9\": \"truck\"\n",
            "  },\n",
            "  \"image_size\": 224,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"airplane\": \"0\",\n",
            "    \"automobile\": \"1\",\n",
            "    \"bird\": \"2\",\n",
            "    \"cat\": \"3\",\n",
            "    \"deer\": \"4\",\n",
            "    \"dog\": \"5\",\n",
            "    \"frog\": \"6\",\n",
            "    \"horse\": \"7\",\n",
            "    \"ship\": \"8\",\n",
            "    \"truck\": \"9\"\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"model_type\": \"vit\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_channels\": 3,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"patch_size\": 16,\n",
            "  \"pooler_act\": \"tanh\",\n",
            "  \"pooler_output_size\": 768,\n",
            "  \"qkv_bias\": true,\n",
            "  \"transformers_version\": \"4.57.0.dev0\"\n",
            "}\n",
            "\n",
            "model.safetensors: 100% 346M/346M [00:03<00:00, 115MB/s]\n",
            "[INFO|modeling_utils.py:1101] 2025-10-02 00:52:22,566 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/b4569560a39a0f1af58e3ddaf17facf20ab919b0/model.safetensors\n",
            "[INFO|modeling_utils.py:5337] 2025-10-02 00:52:22,697 >> Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:5347] 2025-10-02 00:52:22,697 >> Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "preprocessor_config.json: 100% 160/160 [00:00<00:00, 508kB/s]\n",
            "[INFO|image_processing_base.py:383] 2025-10-02 00:52:22,855 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/b4569560a39a0f1af58e3ddaf17facf20ab919b0/preprocessor_config.json\n",
            "[INFO|configuration_utils.py:759] 2025-10-02 00:52:22,907 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/b4569560a39a0f1af58e3ddaf17facf20ab919b0/config.json\n",
            "[INFO|configuration_utils.py:833] 2025-10-02 00:52:22,909 >> Model config ViTConfig {\n",
            "  \"architectures\": [\n",
            "    \"ViTModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"encoder_stride\": 16,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"image_size\": 224,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"model_type\": \"vit\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_channels\": 3,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"patch_size\": 16,\n",
            "  \"pooler_act\": \"tanh\",\n",
            "  \"pooler_output_size\": 768,\n",
            "  \"qkv_bias\": true,\n",
            "  \"transformers_version\": \"4.57.0.dev0\"\n",
            "}\n",
            "\n",
            "[WARNING|image_processing_auto.py:347] 2025-10-02 00:52:22,917 >> Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "[INFO|image_processing_base.py:383] 2025-10-02 00:52:22,992 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/b4569560a39a0f1af58e3ddaf17facf20ab919b0/preprocessor_config.json\n",
            "[INFO|image_processing_utils.py:248] 2025-10-02 00:52:22,992 >> size should be a dictionary on of the following set of keys: ({'width', 'height'}, {'shortest_edge'}, {'shortest_edge', 'longest_edge'}, {'longest_edge'}, {'max_width', 'max_height'}), got 224. Converted to {'height': 224, 'width': 224}.\n",
            "[INFO|image_processing_base.py:428] 2025-10-02 00:52:22,993 >> Image processor ViTImageProcessor {\n",
            "  \"do_convert_rgb\": null,\n",
            "  \"do_normalize\": true,\n",
            "  \"do_rescale\": true,\n",
            "  \"do_resize\": true,\n",
            "  \"image_mean\": [\n",
            "    0.5,\n",
            "    0.5,\n",
            "    0.5\n",
            "  ],\n",
            "  \"image_processor_type\": \"ViTImageProcessor\",\n",
            "  \"image_std\": [\n",
            "    0.5,\n",
            "    0.5,\n",
            "    0.5\n",
            "  ],\n",
            "  \"resample\": 2,\n",
            "  \"rescale_factor\": 0.00392156862745098,\n",
            "  \"size\": {\n",
            "    \"height\": 224,\n",
            "    \"width\": 224\n",
            "  }\n",
            "}\n",
            "\n",
            "2025-10-02 00:52:25.559239: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759366345.839664    4756 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759366345.921837    4756 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759366346.490655    4756 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759366346.490699    4756 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759366346.490704    4756 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759366346.490708    4756 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-02 00:52:26.545220: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "[INFO|trainer.py:2405] 2025-10-02 00:52:33,071 >> ***** Running training *****\n",
            "[INFO|trainer.py:2406] 2025-10-02 00:52:33,071 >>   Num examples = 42,500\n",
            "[INFO|trainer.py:2407] 2025-10-02 00:52:33,071 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:2408] 2025-10-02 00:52:33,071 >>   Instantaneous batch size per device = 16\n",
            "[INFO|trainer.py:2411] 2025-10-02 00:52:33,071 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:2412] 2025-10-02 00:52:33,072 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:2413] 2025-10-02 00:52:33,072 >>   Total optimization steps = 7,971\n",
            "[INFO|trainer.py:2414] 2025-10-02 00:52:33,072 >>   Number of trainable parameters = 85,806,346\n",
            "[INFO|integration_utils.py:858] 2025-10-02 00:52:33,077 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: ^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import sys\n",
        "\n",
        "print(\"--- Bắt đầu QUY TRÌNH CHẠY MÔ PHỎNG VISION TRANSFORMER (ViT) ---\")\n",
        "print(\"--- Code này đã sửa tất cả lỗi bạn đã gặp (đường dẫn, tên cột, xung đột) ---\")\n",
        "\n",
        "# --- BƯỚC 1: Tải Code & Cài đặt Thư viện ---\n",
        "print(\"\\n[BƯỚC 1/3]: Tải dự án và cài đặt phụ thuộc...\")\n",
        "# Xóa thư mục cũ và clone lại\n",
        "if os.path.exists(\"transformers\"):\n",
        "    !rm -rf transformers\n",
        "!git clone https://github.com/huggingface/transformers.git\n",
        "\n",
        "# Di chuyển vào thư mục dự án\n",
        "os.chdir(\"transformers\")\n",
        "print(f\"Đã chuyển sang thư mục: {os.getcwd()}\")\n",
        "\n",
        "# Cài đặt thư viện: dùng --upgrade --force-reinstall để giải quyết triệt để các xung đột\n",
        "!pip install -e \".[testing]\" --upgrade --force-reinstall\n",
        "print(\"[BƯỚC 1 HOÀN TẤT]\")\n",
        "\n",
        "\n",
        "# --- BƯỚC 2: Chạy Mô phỏng Vision Transformer (ViT) ---\n",
        "print(\"\\n[BƯỚC 2/3]: Bắt đầu chạy mô phỏng ViT trên CIFAR-10 (3 epochs)...\")\n",
        "print(\"--- LƯU Ý: Nếu xuất hiện 'wandb: Enter your choice:', hãy gõ 3 và nhấn Enter ---\")\n",
        "# Đây là bước huấn luyện chính, sẽ mất 10-30 phút\n",
        "\n",
        "# Lệnh chạy script huấn luyện với đường dẫn VÀ tên cột chính xác (--image_column_name \"img\")\n",
        "!python examples/pytorch/image-classification/run_image_classification.py \\\n",
        "    --model_name_or_path \"google/vit-base-patch16-224-in21k\" \\\n",
        "    --dataset_name \"cifar10\" \\\n",
        "    --output_dir \"../vit_cifar10_output\" \\\n",
        "    --remove_unused_columns False \\\n",
        "    --do_train --do_eval \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 3 \\\n",
        "    --per_device_train_batch_size 16 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --image_column_name \"img\"\n",
        "\n",
        "print(\"\\n[BƯỚC 2 HOÀN TẤT: Đã chạy xong huấn luyện 3 epochs.]\")\n",
        "\n",
        "# --- BƯỚC 3: Thu thập và Hiển thị Kết quả Cuối cùng ---\n",
        "print(\"\\n[BƯỚC 3/3]: Đọc và hiển thị kết quả cuối cùng...\")\n",
        "# Quay lại thư mục gốc để truy cập thư mục output đã tạo\n",
        "os.chdir(\"../\")\n",
        "\n",
        "output_dir = \"vit_cifar10_output\"\n",
        "eval_results_path = os.path.join(output_dir, \"eval_results.json\")\n",
        "\n",
        "try:\n",
        "    with open(eval_results_path, 'r') as f:\n",
        "        results = json.load(f)\n",
        "\n",
        "    print(\"\\n--- KẾT QUẢ ĐÁNH GIÁ CUỐI CÙNG CỦA MÔ PHỎNG (ViT) ---\")\n",
        "    for key, value in results.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "    print(\"\\nFile kết quả đã được lưu. Chỉ số 'eval_accuracy' là kết quả bạn cần nộp.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Lỗi: Không tìm thấy tệp '{eval_results_path}'. Vui lòng đảm bảo BƯỚC 2 đã chạy HOÀN TẤT 100%.\")\n",
        "\n",
        "print(\"\\n--- QUY TRÌNH KẾT THÚC ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tNWZS46paSL9",
        "outputId": "bf4848fb-52c2-48f2-8336-89132fececd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Bắt đầu QUY TRÌNH CHẠY MÔ PHỎNG VISION TRANSFORMER (ViT) ---\n",
            "--- Code này đã sửa tất cả lỗi bạn đã gặp (đường dẫn, tên cột, xung đột) ---\n",
            "\n",
            "[BƯỚC 1/3]: Tải dự án và cài đặt phụ thuộc...\n",
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 347415, done.\u001b[K\n",
            "remote: Counting objects: 100% (1464/1464), done.\u001b[K\n",
            "remote: Compressing objects: 100% (798/798), done.\u001b[K\n",
            "remote: Total 347415 (delta 1022), reused 666 (delta 666), pack-reused 345951 (from 4)\u001b[K\n",
            "Receiving objects: 100% (347415/347415), 363.61 MiB | 23.08 MiB/s, done.\n",
            "Resolving deltas: 100% (264313/264313), done.\n",
            "Đã chuyển sang thư mục: /content/transformers\n",
            "Obtaining file:///content/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting filelock (from transformers==4.57.0.dev0)\n",
            "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting huggingface-hub==1.0.0.rc2 (from transformers==4.57.0.dev0)\n",
            "  Downloading huggingface_hub-1.0.0rc2-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy>=1.17 (from transformers==4.57.0.dev0)\n",
            "  Downloading numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0 (from transformers==4.57.0.dev0)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyyaml>=5.1 (from transformers==4.57.0.dev0)\n",
            "  Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers==4.57.0.dev0)\n",
            "  Downloading regex-2025.9.18-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests (from transformers==4.57.0.dev0)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers==4.57.0.dev0)\n",
            "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers==4.57.0.dev0)\n",
            "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting tqdm>=4.27 (from transformers==4.57.0.dev0)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub==1.0.0.rc2->transformers==4.57.0.dev0)\n",
            "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from huggingface-hub==1.0.0.rc2->transformers==4.57.0.dev0)\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typer-slim (from huggingface-hub==1.0.0.rc2->transformers==4.57.0.dev0)\n",
            "  Downloading typer_slim-0.19.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub==1.0.0.rc2->transformers==4.57.0.dev0)\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub==1.0.0.rc2->transformers==4.57.0.dev0)\n",
            "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Collecting pytest>=7.2.0 (from transformers==4.57.0.dev0)\n",
            "  Downloading pytest-8.4.2-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting pytest-asyncio (from transformers==4.57.0.dev0)\n",
            "  Downloading pytest_asyncio-1.2.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting pytest-rich (from transformers==4.57.0.dev0)\n",
            "  Downloading pytest_rich-0.2.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting pytest-xdist (from transformers==4.57.0.dev0)\n",
            "  Downloading pytest_xdist-3.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting pytest-order (from transformers==4.57.0.dev0)\n",
            "  Downloading pytest_order-1.3.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting pytest-rerunfailures<16.0 (from transformers==4.57.0.dev0)\n",
            "  Downloading pytest_rerunfailures-15.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting timeout-decorator (from transformers==4.57.0.dev0)\n",
            "  Downloading timeout-decorator-0.5.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting parameterized>=0.9 (from transformers==4.57.0.dev0)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting psutil (from transformers==4.57.0.dev0)\n",
            "  Downloading psutil-7.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
            "Collecting datasets>=2.15.0 (from transformers==4.57.0.dev0)\n",
            "  Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting dill<0.3.5 (from transformers==4.57.0.dev0)\n",
            "  Downloading dill-0.3.4-py2.py3-none-any.whl.metadata (9.6 kB)\n",
            "Collecting evaluate>=0.2.0 (from transformers==4.57.0.dev0)\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pytest-timeout (from transformers==4.57.0.dev0)\n",
            "  Downloading pytest_timeout-2.4.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting ruff==0.13.1 (from transformers==4.57.0.dev0)\n",
            "  Downloading ruff-0.13.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting rouge-score!=0.0.7,!=0.0.8,!=0.1,!=0.1.1 (from transformers==4.57.0.dev0)\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nltk<=3.8.1 (from transformers==4.57.0.dev0)\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting GitPython<3.1.19 (from transformers==4.57.0.dev0)\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting sacremoses (from transformers==4.57.0.dev0)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting rjieba (from transformers==4.57.0.dev0)\n",
            "  Downloading rjieba-0.1.13-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting beautifulsoup4 (from transformers==4.57.0.dev0)\n",
            "  Downloading beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting tensorboard (from transformers==4.57.0.dev0)\n",
            "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting pydantic>=2 (from transformers==4.57.0.dev0)\n",
            "  Downloading pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.4/68.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92,>=0.1.91 (from transformers==4.57.0.dev0)\n",
            "  Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting sacrebleu<2.0.0,>=1.4.12 (from transformers==4.57.0.dev0)\n",
            "  Downloading sacrebleu-1.5.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting libcst (from transformers==4.57.0.dev0)\n",
            "  Downloading libcst-1.8.5-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (15 kB)\n",
            "Collecting faiss-cpu (from transformers==4.57.0.dev0)\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting cookiecutter==1.7.3 (from transformers==4.57.0.dev0)\n",
            "  Downloading cookiecutter-1.7.3-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mistral-common>=1.6.3 (from mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Downloading mistral_common-1.8.5-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting openai>=1.98.0 (from transformers==4.57.0.dev0)\n",
            "  Downloading openai-2.0.1-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting uvicorn (from transformers==4.57.0.dev0)\n",
            "  Downloading uvicorn-0.37.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting fastapi (from transformers==4.57.0.dev0)\n",
            "  Downloading fastapi-0.118.0-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting starlette (from transformers==4.57.0.dev0)\n",
            "  Downloading starlette-0.48.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting torch>=2.2 (from transformers==4.57.0.dev0)\n",
            "  Downloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting accelerate>=0.26.0 (from transformers==4.57.0.dev0)\n",
            "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting binaryornot>=0.4.4 (from cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading binaryornot-0.4.4-py2.py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting Jinja2<4.0.0,>=2.7 (from cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting click>=7.0 (from cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting poyo>=0.5.0 (from cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading poyo-0.5.0-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting jinja2-time>=0.2.0 (from cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading jinja2_time-0.2.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-slugify>=4.0.0 (from cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting six>=1.10 (from cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting pyarrow>=21.0.0 (from datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting pandas (from datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython<3.1.19->transformers==4.57.0.dev0)\n",
            "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting jsonschema>=4.21.1 (from mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting tiktoken>=0.7.0 (from mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Downloading tiktoken-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting pillow>=10.3.0 (from mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Downloading pydantic_extra_types-2.10.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting opencv-python-headless>=4.0.0 (from mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "Collecting joblib (from nltk<=3.8.1->transformers==4.57.0.dev0)\n",
            "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting anyio<5,>=3.5.0 (from openai>=1.98.0->transformers==4.57.0.dev0)\n",
            "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai>=1.98.0->transformers==4.57.0.dev0)\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.98.0->transformers==4.57.0.dev0)\n",
            "  Downloading jiter-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting sniffio (from openai>=1.98.0->transformers==4.57.0.dev0)\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic>=2->transformers==4.57.0.dev0)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic>=2->transformers==4.57.0.dev0)\n",
            "  Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic>=2->transformers==4.57.0.dev0)\n",
            "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting iniconfig>=1 (from pytest>=7.2.0->transformers==4.57.0.dev0)\n",
            "  Downloading iniconfig-2.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting pluggy<2,>=1.5 (from pytest>=7.2.0->transformers==4.57.0.dev0)\n",
            "  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting pygments>=2.7.2 (from pytest>=7.2.0->transformers==4.57.0.dev0)\n",
            "  Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->transformers==4.57.0.dev0)\n",
            "  Downloading charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->transformers==4.57.0.dev0)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.57.0.dev0)\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers==4.57.0.dev0)\n",
            "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting absl-py (from rouge-score!=0.0.7,!=0.0.8,!=0.1,!=0.1.1->transformers==4.57.0.dev0)\n",
            "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting portalocker==2.0.0 (from sacrebleu<2.0.0,>=1.4.12->transformers==4.57.0.dev0)\n",
            "  Downloading portalocker-2.0.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting setuptools (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sympy>=1.13.3 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.4.0 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4->transformers==4.57.0.dev0)\n",
            "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting attrs (from pytest-rich->transformers==4.57.0.dev0)\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting rich (from pytest-rich->transformers==4.57.0.dev0)\n",
            "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting execnet>=2.1 (from pytest-xdist->transformers==4.57.0.dev0)\n",
            "  Downloading execnet-2.1.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard->transformers==4.57.0.dev0)\n",
            "  Downloading grpcio-1.75.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard->transformers==4.57.0.dev0)\n",
            "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard->transformers==4.57.0.dev0)\n",
            "  Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->transformers==4.57.0.dev0)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard->transformers==4.57.0.dev0)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting h11>=0.8 (from uvicorn->transformers==4.57.0.dev0)\n",
            "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting chardet>=3.0.2 (from binaryornot>=0.4.4->cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython<3.1.19->transformers==4.57.0.dev0)\n",
            "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->huggingface-hub==1.0.0.rc2->transformers==4.57.0.dev0)\n",
            "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting MarkupSafe>=2.0 (from Jinja2<4.0.0,>=2.7->cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting arrow (from jinja2-time>=0.2.0->cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.21.1->mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=4.21.1->mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=4.21.1->mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Downloading rpds_py-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading multiprocess-0.70.13-py310-none-any.whl.metadata (6.8 kB)\n",
            "  Downloading multiprocess-0.70.12.2-py39-none-any.whl.metadata (6.9 kB)\n",
            "Collecting numpy>=1.17 (from transformers==4.57.0.dev0)\n",
            "  Downloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting text-unidecode>=1.3 (from python-slugify>=4.0.0->cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->pytest-rich->transformers==4.57.0.dev0)\n",
            "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->pytest-rich->transformers==4.57.0.dev0)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow->jinja2-time>=0.2.0->cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Downloading types_python_dateutil-2.9.0.20250822-py3-none-any.whl.metadata (1.8 kB)\n",
            "Downloading huggingface_hub-1.0.0rc2-py3-none-any.whl (528 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.7/528.7 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cookiecutter-1.7.3-py2.py3-none-any.whl (34 kB)\n",
            "Downloading ruff-0.13.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.9/374.9 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-4.1.1-py3-none-any.whl (503 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.6/503.6 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.1/170.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistral_common-1.8.5-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-2.0.1-py3-none-any.whl (956 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m956.3/956.3 kB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.9/444.9 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest-8.4.2-py3-none-any.whl (365 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.8/365.8 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_rerunfailures-15.1-py3-none-any.whl (13 kB)\n",
            "Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2025.9.18-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (802 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.0/802.0 kB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.8/485.8 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (887.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.9/887.9 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.4/106.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.118.0-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.7/97.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.48.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Downloading libcst-1.8.5-cp312-cp312-manylinux_2_28_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (291 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.2/291.2 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_asyncio-1.2.0-py3-none-any.whl (15 kB)\n",
            "Downloading pytest_order-1.3.0-py3-none-any.whl (14 kB)\n",
            "Downloading pytest_rich-0.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading pytest_timeout-2.4.0-py3-none-any.whl (14 kB)\n",
            "Downloading pytest_xdist-3.8.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rjieba-0.1.13-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m118.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.37.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.0/68.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading binaryornot-0.4.4-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.2/161.2 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.8/151.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.3.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading execnet-2.1.1-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.75.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m123.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iniconfig-2.1.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2_time-0.2.0-py2.py3-none-any.whl (6.4 kB)\n",
            "Downloading jiter-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.9/347.9 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown-3.9-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.12.2-py39-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
            "Downloading poyo-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_extra_types-2.10.5-py3-none-any.whl (38 kB)\n",
            "Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
            "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m117.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m123.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.4/308.4 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer_slim-0.19.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
            "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Downloading rpds_py-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
            "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.8/241.8 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.1/256.1 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.4/224.4 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20250822-py3-none-any.whl (17 kB)\n",
            "Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.6/355.6 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers, rouge-score, timeout-decorator\n",
            "  Building editable for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.57.0.dev0-0.editable-py3-none-any.whl size=14982 sha256=29dddfe6e80ff6ef1cb3de3732d6676008f2e57be9f680cd895f5390e5b76945\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sfvde6o5/wheels/5d/95/aa/7bf76982b5186f967ea8b0d48a21290fa6c5c65b1e12ae5460\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=197abaaafdd254b7b2397a3b734d39e93f4b3bbc6a5192aa48cc60be813a5f67\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
            "  Building wheel for timeout-decorator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for timeout-decorator: filename=timeout_decorator-0.5.0-py3-none-any.whl size=5006 sha256=48ad7854381a81071fc8dd465b25e24522fb3ed8bca4de18712b6b5626ee17d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/4d/6a/e3/c4f2cdd67648203ccf069daa31c3935a5c74ec04cccbac9411\n",
            "Successfully built transformers rouge-score timeout-decorator\n",
            "Installing collected packages: timeout-decorator, text-unidecode, rjieba, pytz, portalocker, nvidia-cusparselt-cu12, mpmath, xxhash, urllib3, tzdata, typing-extensions, types-python-dateutil, tqdm, tensorboard-data-server, sympy, soupsieve, sniffio, smmap, six, setuptools, sentencepiece, safetensors, sacrebleu, ruff, rpds-py, regex, pyyaml, python-slugify, pygments, pycountry, pyarrow, psutil, protobuf, propcache, poyo, pluggy, pillow, parameterized, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multidict, mdurl, MarkupSafe, markdown, joblib, jiter, iniconfig, idna, hf-xet, h11, fsspec, frozenlist, filelock, execnet, distro, dill, click, charset_normalizer, chardet, certifi, attrs, annotated-types, aiohappyeyeballs, absl-py, yarl, werkzeug, uvicorn, typing-inspection, typer-slim, triton, sacremoses, requests, referencing, python-dateutil, pytest, pydantic-core, opencv-python-headless, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nltk, multiprocess, markdown-it-py, libcst, Jinja2, httpcore, grpcio, gitdb, faiss-cpu, binaryornot, beautifulsoup4, anyio, aiosignal, tiktoken, tensorboard, starlette, rouge-score, rich, pytest-xdist, pytest-timeout, pytest-rerunfailures, pytest-order, pytest-asyncio, pydantic, pandas, nvidia-cusolver-cu12, jsonschema-specifications, httpx, GitPython, arrow, aiohttp, torch, pytest-rich, pydantic-extra-types, openai, jsonschema, jinja2-time, huggingface-hub, fastapi, tokenizers, datasets, cookiecutter, accelerate, transformers, mistral-common, evaluate\n",
            "  Attempting uninstall: text-unidecode\n",
            "    Found existing installation: text-unidecode 1.3\n",
            "    Uninstalling text-unidecode-1.3:\n",
            "      Successfully uninstalled text-unidecode-1.3\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: xxhash\n",
            "    Found existing installation: xxhash 3.5.0\n",
            "    Uninstalling xxhash-3.5.0:\n",
            "      Successfully uninstalled xxhash-3.5.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: types-python-dateutil\n",
            "    Found existing installation: types-python-dateutil 2.9.0.20250822\n",
            "    Uninstalling types-python-dateutil-2.9.0.20250822:\n",
            "      Successfully uninstalled types-python-dateutil-2.9.0.20250822\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "  Attempting uninstall: soupsieve\n",
            "    Found existing installation: soupsieve 2.8\n",
            "    Uninstalling soupsieve-2.8:\n",
            "      Successfully uninstalled soupsieve-2.8\n",
            "  Attempting uninstall: sniffio\n",
            "    Found existing installation: sniffio 1.3.1\n",
            "    Uninstalling sniffio-1.3.1:\n",
            "      Successfully uninstalled sniffio-1.3.1\n",
            "  Attempting uninstall: smmap\n",
            "    Found existing installation: smmap 5.0.2\n",
            "    Uninstalling smmap-5.0.2:\n",
            "      Successfully uninstalled smmap-5.0.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.2.1\n",
            "    Uninstalling sentencepiece-0.2.1:\n",
            "      Successfully uninstalled sentencepiece-0.2.1\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.6.2\n",
            "    Uninstalling safetensors-0.6.2:\n",
            "      Successfully uninstalled safetensors-0.6.2\n",
            "  Attempting uninstall: ruff\n",
            "    Found existing installation: ruff 0.13.0\n",
            "    Uninstalling ruff-0.13.0:\n",
            "      Successfully uninstalled ruff-0.13.0\n",
            "  Attempting uninstall: rpds-py\n",
            "    Found existing installation: rpds-py 0.27.1\n",
            "    Uninstalling rpds-py-0.27.1:\n",
            "      Successfully uninstalled rpds-py-0.27.1\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: python-slugify\n",
            "    Found existing installation: python-slugify 8.0.4\n",
            "    Uninstalling python-slugify-8.0.4:\n",
            "      Successfully uninstalled python-slugify-8.0.4\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.19.2\n",
            "    Uninstalling Pygments-2.19.2:\n",
            "      Successfully uninstalled Pygments-2.19.2\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: propcache\n",
            "    Found existing installation: propcache 0.3.2\n",
            "    Uninstalling propcache-0.3.2:\n",
            "      Successfully uninstalled propcache-0.3.2\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 1.6.0\n",
            "    Uninstalling pluggy-1.6.0:\n",
            "      Successfully uninstalled pluggy-1.6.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.5\n",
            "    Uninstalling networkx-3.5:\n",
            "      Successfully uninstalled networkx-3.5\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.6.4\n",
            "    Uninstalling multidict-6.6.4:\n",
            "      Successfully uninstalled multidict-6.6.4\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.9\n",
            "    Uninstalling Markdown-3.9:\n",
            "      Successfully uninstalled Markdown-3.9\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.5.2\n",
            "    Uninstalling joblib-1.5.2:\n",
            "      Successfully uninstalled joblib-1.5.2\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.11.0\n",
            "    Uninstalling jiter-0.11.0:\n",
            "      Successfully uninstalled jiter-0.11.0\n",
            "  Attempting uninstall: iniconfig\n",
            "    Found existing installation: iniconfig 2.1.0\n",
            "    Uninstalling iniconfig-2.1.0:\n",
            "      Successfully uninstalled iniconfig-2.1.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: hf-xet\n",
            "    Found existing installation: hf-xet 1.1.10\n",
            "    Uninstalling hf-xet-1.1.10:\n",
            "      Successfully uninstalled hf-xet-1.1.10\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.16.0\n",
            "    Uninstalling h11-0.16.0:\n",
            "      Successfully uninstalled h11-0.16.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: frozenlist\n",
            "    Found existing installation: frozenlist 1.7.0\n",
            "    Uninstalling frozenlist-1.7.0:\n",
            "      Successfully uninstalled frozenlist-1.7.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.19.1\n",
            "    Uninstalling filelock-3.19.1:\n",
            "      Successfully uninstalled filelock-3.19.1\n",
            "  Attempting uninstall: distro\n",
            "    Found existing installation: distro 1.9.0\n",
            "    Uninstalling distro-1.9.0:\n",
            "      Successfully uninstalled distro-1.9.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.8\n",
            "    Uninstalling dill-0.3.8:\n",
            "      Successfully uninstalled dill-0.3.8\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.2.1\n",
            "    Uninstalling click-8.2.1:\n",
            "      Successfully uninstalled click-8.2.1\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.3\n",
            "    Uninstalling charset-normalizer-3.4.3:\n",
            "      Successfully uninstalled charset-normalizer-3.4.3\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.8.3\n",
            "    Uninstalling certifi-2025.8.3:\n",
            "      Successfully uninstalled certifi-2025.8.3\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.3.0\n",
            "    Uninstalling attrs-25.3.0:\n",
            "      Successfully uninstalled attrs-25.3.0\n",
            "  Attempting uninstall: annotated-types\n",
            "    Found existing installation: annotated-types 0.7.0\n",
            "    Uninstalling annotated-types-0.7.0:\n",
            "      Successfully uninstalled annotated-types-0.7.0\n",
            "  Attempting uninstall: aiohappyeyeballs\n",
            "    Found existing installation: aiohappyeyeballs 2.6.1\n",
            "    Uninstalling aiohappyeyeballs-2.6.1:\n",
            "      Successfully uninstalled aiohappyeyeballs-2.6.1\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.20.1\n",
            "    Uninstalling yarl-1.20.1:\n",
            "      Successfully uninstalled yarl-1.20.1\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: uvicorn\n",
            "    Found existing installation: uvicorn 0.35.0\n",
            "    Uninstalling uvicorn-0.35.0:\n",
            "      Successfully uninstalled uvicorn-0.35.0\n",
            "  Attempting uninstall: typing-inspection\n",
            "    Found existing installation: typing-inspection 0.4.1\n",
            "    Uninstalling typing-inspection-0.4.1:\n",
            "      Successfully uninstalled typing-inspection-0.4.1\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: referencing\n",
            "    Found existing installation: referencing 0.36.2\n",
            "    Uninstalling referencing-0.36.2:\n",
            "      Successfully uninstalled referencing-0.36.2\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 8.4.2\n",
            "    Uninstalling pytest-8.4.2:\n",
            "      Successfully uninstalled pytest-8.4.2\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.9.1\n",
            "    Uninstalling nltk-3.9.1:\n",
            "      Successfully uninstalled nltk-3.9.1\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.16\n",
            "    Uninstalling multiprocess-0.70.16:\n",
            "      Successfully uninstalled multiprocess-0.70.16\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 4.0.0\n",
            "    Uninstalling markdown-it-py-4.0.0:\n",
            "      Successfully uninstalled markdown-it-py-4.0.0\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.9\n",
            "    Uninstalling httpcore-1.0.9:\n",
            "      Successfully uninstalled httpcore-1.0.9\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.75.0\n",
            "    Uninstalling grpcio-1.75.0:\n",
            "      Successfully uninstalled grpcio-1.75.0\n",
            "  Attempting uninstall: gitdb\n",
            "    Found existing installation: gitdb 4.0.12\n",
            "    Uninstalling gitdb-4.0.12:\n",
            "      Successfully uninstalled gitdb-4.0.12\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.13.5\n",
            "    Uninstalling beautifulsoup4-4.13.5:\n",
            "      Successfully uninstalled beautifulsoup4-4.13.5\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 4.10.0\n",
            "    Uninstalling anyio-4.10.0:\n",
            "      Successfully uninstalled anyio-4.10.0\n",
            "  Attempting uninstall: aiosignal\n",
            "    Found existing installation: aiosignal 1.4.0\n",
            "    Uninstalling aiosignal-1.4.0:\n",
            "      Successfully uninstalled aiosignal-1.4.0\n",
            "  Attempting uninstall: tiktoken\n",
            "    Found existing installation: tiktoken 0.11.0\n",
            "    Uninstalling tiktoken-0.11.0:\n",
            "      Successfully uninstalled tiktoken-0.11.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.19.0\n",
            "    Uninstalling tensorboard-2.19.0:\n",
            "      Successfully uninstalled tensorboard-2.19.0\n",
            "  Attempting uninstall: starlette\n",
            "    Found existing installation: starlette 0.48.0\n",
            "    Uninstalling starlette-0.48.0:\n",
            "      Successfully uninstalled starlette-0.48.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.9\n",
            "    Uninstalling pydantic-2.11.9:\n",
            "      Successfully uninstalled pydantic-2.11.9\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: jsonschema-specifications\n",
            "    Found existing installation: jsonschema-specifications 2025.9.1\n",
            "    Uninstalling jsonschema-specifications-2025.9.1:\n",
            "      Successfully uninstalled jsonschema-specifications-2025.9.1\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: GitPython\n",
            "    Found existing installation: GitPython 3.1.45\n",
            "    Uninstalling GitPython-3.1.45:\n",
            "      Successfully uninstalled GitPython-3.1.45\n",
            "  Attempting uninstall: arrow\n",
            "    Found existing installation: arrow 1.3.0\n",
            "    Uninstalling arrow-1.3.0:\n",
            "      Successfully uninstalled arrow-1.3.0\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.12.15\n",
            "    Uninstalling aiohttp-3.12.15:\n",
            "      Successfully uninstalled aiohttp-3.12.15\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.108.0\n",
            "    Uninstalling openai-1.108.0:\n",
            "      Successfully uninstalled openai-1.108.0\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.25.1\n",
            "    Uninstalling jsonschema-4.25.1:\n",
            "      Successfully uninstalled jsonschema-4.25.1\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.35.0\n",
            "    Uninstalling huggingface-hub-0.35.0:\n",
            "      Successfully uninstalled huggingface-hub-0.35.0\n",
            "  Attempting uninstall: fastapi\n",
            "    Found existing installation: fastapi 0.116.2\n",
            "    Uninstalling fastapi-0.116.2:\n",
            "      Successfully uninstalled fastapi-0.116.2\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.0\n",
            "    Uninstalling tokenizers-0.22.0:\n",
            "      Successfully uninstalled tokenizers-0.22.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.10.1\n",
            "    Uninstalling accelerate-1.10.1:\n",
            "      Successfully uninstalled accelerate-1.10.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.56.1\n",
            "    Uninstalling transformers-4.56.1:\n",
            "      Successfully uninstalled transformers-4.56.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.32.1 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.32.1 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\n",
            "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
            "bigframes 2.21.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.32.1 which is incompatible.\n",
            "tensorflow 2.19.0 requires tensorboard~=2.19.0, but you have tensorboard 2.20.0 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "gradio 5.46.0 requires huggingface-hub<1.0,>=0.33.5, but you have huggingface-hub 1.0.0rc2 which is incompatible.\n",
            "textblob 0.19.0 requires nltk>=3.9, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.18 Jinja2-3.1.6 MarkupSafe-3.0.3 absl-py-2.3.1 accelerate-1.10.1 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 annotated-types-0.7.0 anyio-4.11.0 arrow-1.3.0 attrs-25.3.0 beautifulsoup4-4.14.2 binaryornot-0.4.4 certifi-2025.8.3 chardet-5.2.0 charset_normalizer-3.4.3 click-8.3.0 cookiecutter-1.7.3 datasets-4.1.1 dill-0.3.4 distro-1.9.0 evaluate-0.4.6 execnet-2.1.1 faiss-cpu-1.12.0 fastapi-0.118.0 filelock-3.19.1 frozenlist-1.7.0 fsspec-2025.9.0 gitdb-4.0.12 grpcio-1.75.1 h11-0.16.0 hf-xet-1.1.10 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-1.0.0rc2 idna-3.10 iniconfig-2.1.0 jinja2-time-0.2.0 jiter-0.11.0 joblib-1.5.2 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 libcst-1.8.5 markdown-3.9 markdown-it-py-4.0.0 mdurl-0.1.2 mistral-common-1.8.5 mpmath-1.3.0 multidict-6.6.4 multiprocess-0.70.12.2 networkx-3.5 nltk-3.8.1 numpy-2.2.6 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 openai-2.0.1 opencv-python-headless-4.12.0.88 packaging-25.0 pandas-2.3.3 parameterized-0.9.0 pillow-11.3.0 pluggy-1.6.0 portalocker-2.0.0 poyo-0.5.0 propcache-0.3.2 protobuf-6.32.1 psutil-7.1.0 pyarrow-21.0.0 pycountry-24.6.1 pydantic-2.11.9 pydantic-core-2.33.2 pydantic-extra-types-2.10.5 pygments-2.19.2 pytest-8.4.2 pytest-asyncio-1.2.0 pytest-order-1.3.0 pytest-rerunfailures-15.1 pytest-rich-0.2.0 pytest-timeout-2.4.0 pytest-xdist-3.8.0 python-dateutil-2.9.0.post0 python-slugify-8.0.4 pytz-2025.2 pyyaml-6.0.3 referencing-0.36.2 regex-2025.9.18 requests-2.32.5 rich-14.1.0 rjieba-0.1.13 rouge-score-0.1.2 rpds-py-0.27.1 ruff-0.13.1 sacrebleu-1.5.1 sacremoses-0.1.1 safetensors-0.6.2 sentencepiece-0.2.1 setuptools-80.9.0 six-1.17.0 smmap-5.0.2 sniffio-1.3.1 soupsieve-2.8 starlette-0.48.0 sympy-1.14.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 text-unidecode-1.3 tiktoken-0.11.0 timeout-decorator-0.5.0 tokenizers-0.22.1 torch-2.8.0 tqdm-4.67.1 transformers-4.57.0.dev0 triton-3.4.0 typer-slim-0.19.2 types-python-dateutil-2.9.0.20250822 typing-extensions-4.15.0 typing-inspection-0.4.2 tzdata-2025.2 urllib3-2.5.0 uvicorn-0.37.0 werkzeug-3.1.3 xxhash-3.5.0 yarl-1.20.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "certifi",
                  "dateutil",
                  "google",
                  "numpy",
                  "packaging",
                  "psutil",
                  "six"
                ]
              },
              "id": "a8e34f7c459c43e88c8ee4dd9873f31a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BƯỚC 1 HOÀN TẤT]\n",
            "\n",
            "[BƯỚC 2/3]: Bắt đầu chạy mô phỏng ViT trên CIFAR-10 (3 epochs)...\n",
            "--- LƯU Ý: Nếu xuất hiện 'wandb: Enter your choice:', hãy gõ 3 và nhấn Enter ---\n",
            "^C\n",
            "\n",
            "[BƯỚC 2 HOÀN TẤT: Đã chạy xong huấn luyện 3 epochs.]\n",
            "\n",
            "[BƯỚC 3/3]: Đọc và hiển thị kết quả cuối cùng...\n",
            "Lỗi: Không tìm thấy tệp 'vit_cifar10_output/eval_results.json'. Vui lòng đảm bảo BƯỚC 2 đã chạy HOÀN TẤT 100%.\n",
            "\n",
            "--- QUY TRÌNH KẾT THÚC ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0itgVStb_y-",
        "outputId": "b8694dac-ab36-4e1d-bc01-3d6a7ac6fb8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã chuyển sang thư mục: /content/transformers\n",
            "--- Bắt đầu chạy lại mô phỏng Vision Transformer (ViT) ---\n",
            "--- Vui lòng chờ cho đến khi quá trình này hoàn tất 100% (sau Epoch 3/3) ---\n",
            "WARNING:__main__:Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "INFO:__main__:Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=True,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=IntervalStrategy.NO,\n",
            "eval_use_gather_object=False,\n",
            "fp16=False,\n",
            "fp16_full_eval=False,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=None,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_num_input_tokens_seen=no,\n",
            "include_tokens_per_second=None,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=../vit_cifar10_output/runs/Oct02_01-01-26_2c96597a03ea,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "num_train_epochs=3.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH_FUSED,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=../vit_cifar10_output,\n",
            "overwrite_output_dir=True,\n",
            "parallelism_config=None,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=16,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=False,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=None,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_liger_kernel=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "README.md: 5.16kB [00:00, 13.1MB/s]\n",
            "plain_text/train-00000-of-00001.parquet: 100% 120M/120M [00:01<00:00, 95.3MB/s]\n",
            "plain_text/test-00000-of-00001.parquet: 100% 23.9M/23.9M [00:00<00:00, 52.8MB/s]\n",
            "Generating train split: 100% 50000/50000 [00:00<00:00, 111893.70 examples/s]\n",
            "Generating test split: 100% 10000/10000 [00:00<00:00, 119679.96 examples/s]\n",
            "Downloading builder script: 4.20kB [00:00, 14.2MB/s]\n",
            "config.json: 100% 502/502 [00:00<00:00, 2.90MB/s]\n",
            "[INFO|configuration_utils.py:759] 2025-10-02 01:02:00,501 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/b4569560a39a0f1af58e3ddaf17facf20ab919b0/config.json\n",
            "[INFO|configuration_utils.py:833] 2025-10-02 01:02:00,502 >> Model config ViTConfig {\n",
            "  \"architectures\": [\n",
            "    \"ViTModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"encoder_stride\": 16,\n",
            "  \"finetuning_task\": \"image-classification\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"airplane\",\n",
            "    \"1\": \"automobile\",\n",
            "    \"2\": \"bird\",\n",
            "    \"3\": \"cat\",\n",
            "    \"4\": \"deer\",\n",
            "    \"5\": \"dog\",\n",
            "    \"6\": \"frog\",\n",
            "    \"7\": \"horse\",\n",
            "    \"8\": \"ship\",\n",
            "    \"9\": \"truck\"\n",
            "  },\n",
            "  \"image_size\": 224,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"airplane\": \"0\",\n",
            "    \"automobile\": \"1\",\n",
            "    \"bird\": \"2\",\n",
            "    \"cat\": \"3\",\n",
            "    \"deer\": \"4\",\n",
            "    \"dog\": \"5\",\n",
            "    \"frog\": \"6\",\n",
            "    \"horse\": \"7\",\n",
            "    \"ship\": \"8\",\n",
            "    \"truck\": \"9\"\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"model_type\": \"vit\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_channels\": 3,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"patch_size\": 16,\n",
            "  \"pooler_act\": \"tanh\",\n",
            "  \"pooler_output_size\": 768,\n",
            "  \"qkv_bias\": true,\n",
            "  \"transformers_version\": \"4.57.0.dev0\"\n",
            "}\n",
            "\n",
            "model.safetensors: 100% 346M/346M [00:06<00:00, 49.9MB/s]\n",
            "[INFO|modeling_utils.py:1101] 2025-10-02 01:02:07,721 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/b4569560a39a0f1af58e3ddaf17facf20ab919b0/model.safetensors\n",
            "[INFO|modeling_utils.py:5337] 2025-10-02 01:02:07,799 >> Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:5347] 2025-10-02 01:02:07,799 >> Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "preprocessor_config.json: 100% 160/160 [00:00<00:00, 968kB/s]\n",
            "[INFO|image_processing_base.py:383] 2025-10-02 01:02:08,089 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/b4569560a39a0f1af58e3ddaf17facf20ab919b0/preprocessor_config.json\n",
            "[INFO|configuration_utils.py:759] 2025-10-02 01:02:08,192 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/b4569560a39a0f1af58e3ddaf17facf20ab919b0/config.json\n",
            "[INFO|configuration_utils.py:833] 2025-10-02 01:02:08,193 >> Model config ViTConfig {\n",
            "  \"architectures\": [\n",
            "    \"ViTModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"encoder_stride\": 16,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"image_size\": 224,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"model_type\": \"vit\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_channels\": 3,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"patch_size\": 16,\n",
            "  \"pooler_act\": \"tanh\",\n",
            "  \"pooler_output_size\": 768,\n",
            "  \"qkv_bias\": true,\n",
            "  \"transformers_version\": \"4.57.0.dev0\"\n",
            "}\n",
            "\n",
            "[WARNING|image_processing_auto.py:347] 2025-10-02 01:02:08,196 >> Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "[INFO|image_processing_base.py:383] 2025-10-02 01:02:08,405 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/b4569560a39a0f1af58e3ddaf17facf20ab919b0/preprocessor_config.json\n",
            "[INFO|image_processing_utils.py:248] 2025-10-02 01:02:08,405 >> size should be a dictionary on of the following set of keys: ({'height', 'width'}, {'shortest_edge'}, {'longest_edge', 'shortest_edge'}, {'longest_edge'}, {'max_width', 'max_height'}), got 224. Converted to {'height': 224, 'width': 224}.\n",
            "[INFO|image_processing_base.py:428] 2025-10-02 01:02:08,405 >> Image processor ViTImageProcessor {\n",
            "  \"do_convert_rgb\": null,\n",
            "  \"do_normalize\": true,\n",
            "  \"do_rescale\": true,\n",
            "  \"do_resize\": true,\n",
            "  \"image_mean\": [\n",
            "    0.5,\n",
            "    0.5,\n",
            "    0.5\n",
            "  ],\n",
            "  \"image_processor_type\": \"ViTImageProcessor\",\n",
            "  \"image_std\": [\n",
            "    0.5,\n",
            "    0.5,\n",
            "    0.5\n",
            "  ],\n",
            "  \"resample\": 2,\n",
            "  \"rescale_factor\": 0.00392156862745098,\n",
            "  \"size\": {\n",
            "    \"height\": 224,\n",
            "    \"width\": 224\n",
            "  }\n",
            "}\n",
            "\n",
            "2025-10-02 01:02:10.423760: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759366930.685905    2650 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759366930.754380    2650 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759366931.273487    2650 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759366931.273533    2650 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759366931.273538    2650 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759366931.273542    2650 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-02 01:02:11.320311: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "[INFO|trainer.py:2405] 2025-10-02 01:02:17,265 >> ***** Running training *****\n",
            "[INFO|trainer.py:2406] 2025-10-02 01:02:17,265 >>   Num examples = 42,500\n",
            "[INFO|trainer.py:2407] 2025-10-02 01:02:17,265 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:2408] 2025-10-02 01:02:17,265 >>   Instantaneous batch size per device = 16\n",
            "[INFO|trainer.py:2411] 2025-10-02 01:02:17,265 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:2412] 2025-10-02 01:02:17,265 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:2413] 2025-10-02 01:02:17,265 >>   Total optimization steps = 7,971\n",
            "[INFO|trainer.py:2414] 2025-10-02 01:02:17,266 >>   Number of trainable parameters = 85,806,346\n",
            "[INFO|integration_utils.py:858] 2025-10-02 01:02:17,280 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/transformers/wandb/offline-run-20251002_010235-ujjqqy2c\u001b[0m\n",
            "{'loss': 1.2855, 'grad_norm': 3.6517221927642822, 'learning_rate': 1.8747961359929748e-05, 'epoch': 0.19}\n",
            "  6% 500/7971 [04:31<1:08:32,  1.82it/s][INFO|trainer.py:4133] 2025-10-02 01:07:09,265 >> Saving model checkpoint to ../vit_cifar10_output/checkpoint-500\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 01:07:09,268 >> Configuration saved in ../vit_cifar10_output/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 01:07:14,898 >> Model weights saved in ../vit_cifar10_output/checkpoint-500/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 01:07:14,899 >> Image processor saved in ../vit_cifar10_output/checkpoint-500/preprocessor_config.json\n",
            "{'loss': 0.5801, 'grad_norm': 1.7420997619628906, 'learning_rate': 1.749341362438841e-05, 'epoch': 0.38}\n",
            " 13% 1000/7971 [09:24<1:06:54,  1.74it/s][INFO|trainer.py:4133] 2025-10-02 01:12:02,007 >> Saving model checkpoint to ../vit_cifar10_output/checkpoint-1000\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 01:12:02,009 >> Configuration saved in ../vit_cifar10_output/checkpoint-1000/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 01:12:05,989 >> Model weights saved in ../vit_cifar10_output/checkpoint-1000/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 01:12:05,991 >> Image processor saved in ../vit_cifar10_output/checkpoint-1000/preprocessor_config.json\n",
            "{'loss': 0.4509, 'grad_norm': 9.295042037963867, 'learning_rate': 1.6238865888847073e-05, 'epoch': 0.56}\n",
            " 19% 1500/7971 [14:22<1:02:15,  1.73it/s][INFO|trainer.py:4133] 2025-10-02 01:17:00,335 >> Saving model checkpoint to ../vit_cifar10_output/checkpoint-1500\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 01:17:00,338 >> Configuration saved in ../vit_cifar10_output/checkpoint-1500/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 01:17:01,294 >> Model weights saved in ../vit_cifar10_output/checkpoint-1500/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 01:17:01,296 >> Image processor saved in ../vit_cifar10_output/checkpoint-1500/preprocessor_config.json\n",
            "{'loss': 0.3824, 'grad_norm': 2.5790815353393555, 'learning_rate': 1.4984318153305734e-05, 'epoch': 0.75}\n",
            " 25% 2000/7971 [19:14<56:35,  1.76it/s][INFO|trainer.py:4133] 2025-10-02 01:21:51,927 >> Saving model checkpoint to ../vit_cifar10_output/checkpoint-2000\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 01:21:51,930 >> Configuration saved in ../vit_cifar10_output/checkpoint-2000/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 01:21:57,596 >> Model weights saved in ../vit_cifar10_output/checkpoint-2000/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 01:21:57,597 >> Image processor saved in ../vit_cifar10_output/checkpoint-2000/preprocessor_config.json\n",
            "{'loss': 0.3363, 'grad_norm': 3.5525355339050293, 'learning_rate': 1.3729770417764396e-05, 'epoch': 0.94}\n",
            " 31% 2500/7971 [24:09<52:46,  1.73it/s][INFO|trainer.py:4133] 2025-10-02 01:26:47,771 >> Saving model checkpoint to ../vit_cifar10_output/checkpoint-2500\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 01:26:47,774 >> Configuration saved in ../vit_cifar10_output/checkpoint-2500/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 01:26:54,577 >> Model weights saved in ../vit_cifar10_output/checkpoint-2500/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 01:26:54,578 >> Image processor saved in ../vit_cifar10_output/checkpoint-2500/preprocessor_config.json\n",
            "{'loss': 0.3071, 'grad_norm': 0.16956105828285217, 'learning_rate': 1.247522268222306e-05, 'epoch': 1.13}\n",
            " 38% 3000/7971 [29:04<47:26,  1.75it/s][INFO|trainer.py:4133] 2025-10-02 01:31:42,832 >> Saving model checkpoint to ../vit_cifar10_output/checkpoint-3000\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 01:31:42,836 >> Configuration saved in ../vit_cifar10_output/checkpoint-3000/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 01:31:49,482 >> Model weights saved in ../vit_cifar10_output/checkpoint-3000/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 01:31:49,484 >> Image processor saved in ../vit_cifar10_output/checkpoint-3000/preprocessor_config.json\n",
            "{'loss': 0.2898, 'grad_norm': 7.409353256225586, 'learning_rate': 1.1220674946681723e-05, 'epoch': 1.32}\n",
            " 44% 3500/7971 [34:01<42:38,  1.75it/s][INFO|trainer.py:4133] 2025-10-02 01:36:39,235 >> Saving model checkpoint to ../vit_cifar10_output/checkpoint-3500\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 01:36:39,237 >> Configuration saved in ../vit_cifar10_output/checkpoint-3500/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 01:36:40,204 >> Model weights saved in ../vit_cifar10_output/checkpoint-3500/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 01:36:40,206 >> Image processor saved in ../vit_cifar10_output/checkpoint-3500/preprocessor_config.json\n",
            "{'loss': 0.2826, 'grad_norm': 1.1218135356903076, 'learning_rate': 9.966127211140385e-06, 'epoch': 1.51}\n",
            " 50% 4000/7971 [38:49<37:39,  1.76it/s][INFO|trainer.py:4133] 2025-10-02 01:41:27,063 >> Saving model checkpoint to ../vit_cifar10_output/checkpoint-4000\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 01:41:27,065 >> Configuration saved in ../vit_cifar10_output/checkpoint-4000/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 01:41:31,152 >> Model weights saved in ../vit_cifar10_output/checkpoint-4000/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 01:41:31,153 >> Image processor saved in ../vit_cifar10_output/checkpoint-4000/preprocessor_config.json\n",
            "{'loss': 0.2685, 'grad_norm': 19.125795364379883, 'learning_rate': 8.711579475599046e-06, 'epoch': 1.69}\n",
            " 56% 4500/7971 [43:43<33:10,  1.74it/s][INFO|trainer.py:4133] 2025-10-02 01:46:21,606 >> Saving model checkpoint to ../vit_cifar10_output/checkpoint-4500\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 01:46:21,609 >> Configuration saved in ../vit_cifar10_output/checkpoint-4500/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 01:46:28,122 >> Model weights saved in ../vit_cifar10_output/checkpoint-4500/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 01:46:28,123 >> Image processor saved in ../vit_cifar10_output/checkpoint-4500/preprocessor_config.json\n",
            "{'loss': 0.2647, 'grad_norm': 9.40728759765625, 'learning_rate': 7.4570317400577095e-06, 'epoch': 1.88}\n",
            " 63% 5000/7971 [48:38<28:20,  1.75it/s][INFO|trainer.py:4133] 2025-10-02 01:51:16,516 >> Saving model checkpoint to ../vit_cifar10_output/checkpoint-5000\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 01:51:16,518 >> Configuration saved in ../vit_cifar10_output/checkpoint-5000/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 01:51:22,987 >> Model weights saved in ../vit_cifar10_output/checkpoint-5000/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 01:51:22,989 >> Image processor saved in ../vit_cifar10_output/checkpoint-5000/preprocessor_config.json\n",
            "{'loss': 0.2505, 'grad_norm': 7.69841194152832, 'learning_rate': 6.202484004516373e-06, 'epoch': 2.07}\n",
            " 69% 5500/7971 [53:31<22:58,  1.79it/s][INFO|trainer.py:4133] 2025-10-02 01:56:09,397 >> Saving model checkpoint to ../vit_cifar10_output/checkpoint-5500\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 01:56:09,400 >> Configuration saved in ../vit_cifar10_output/checkpoint-5500/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 01:56:15,878 >> Model weights saved in ../vit_cifar10_output/checkpoint-5500/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 01:56:15,880 >> Image processor saved in ../vit_cifar10_output/checkpoint-5500/preprocessor_config.json\n",
            "{'loss': 0.2278, 'grad_norm': 3.9584386348724365, 'learning_rate': 4.947936268975035e-06, 'epoch': 2.26}\n",
            " 75% 6000/7971 [58:20<18:38,  1.76it/s][INFO|trainer.py:4133] 2025-10-02 02:00:58,779 >> Saving model checkpoint to ../vit_cifar10_output/checkpoint-6000\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 02:00:58,782 >> Configuration saved in ../vit_cifar10_output/checkpoint-6000/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 02:01:04,613 >> Model weights saved in ../vit_cifar10_output/checkpoint-6000/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 02:01:04,616 >> Image processor saved in ../vit_cifar10_output/checkpoint-6000/preprocessor_config.json\n",
            "{'loss': 0.2197, 'grad_norm': 1.9003808498382568, 'learning_rate': 3.6933885334336973e-06, 'epoch': 2.45}\n",
            " 82% 6500/7971 [1:03:19<14:06,  1.74it/s][INFO|trainer.py:4133] 2025-10-02 02:05:57,791 >> Saving model checkpoint to ../vit_cifar10_output/checkpoint-6500\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 02:05:57,793 >> Configuration saved in ../vit_cifar10_output/checkpoint-6500/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 02:06:03,614 >> Model weights saved in ../vit_cifar10_output/checkpoint-6500/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 02:06:03,622 >> Image processor saved in ../vit_cifar10_output/checkpoint-6500/preprocessor_config.json\n",
            "{'loss': 0.2244, 'grad_norm': 5.799417495727539, 'learning_rate': 2.43884079789236e-06, 'epoch': 2.63}\n",
            " 88% 7000/7971 [1:08:13<09:15,  1.75it/s][INFO|trainer.py:4133] 2025-10-02 02:10:51,661 >> Saving model checkpoint to ../vit_cifar10_output/checkpoint-7000\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 02:10:51,663 >> Configuration saved in ../vit_cifar10_output/checkpoint-7000/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 02:10:52,924 >> Model weights saved in ../vit_cifar10_output/checkpoint-7000/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 02:10:52,926 >> Image processor saved in ../vit_cifar10_output/checkpoint-7000/preprocessor_config.json\n",
            "{'loss': 0.2216, 'grad_norm': 6.391155242919922, 'learning_rate': 1.1842930623510226e-06, 'epoch': 2.82}\n",
            " 94% 7500/7971 [1:13:02<04:31,  1.74it/s][INFO|trainer.py:4133] 2025-10-02 02:15:40,842 >> Saving model checkpoint to ../vit_cifar10_output/checkpoint-7500\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 02:15:40,845 >> Configuration saved in ../vit_cifar10_output/checkpoint-7500/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 02:15:47,322 >> Model weights saved in ../vit_cifar10_output/checkpoint-7500/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 02:15:47,323 >> Image processor saved in ../vit_cifar10_output/checkpoint-7500/preprocessor_config.json\n",
            "100% 7971/7971 [1:17:40<00:00,  2.26it/s][INFO|trainer.py:4133] 2025-10-02 02:20:18,793 >> Saving model checkpoint to ../vit_cifar10_output/checkpoint-7971\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 02:20:18,796 >> Configuration saved in ../vit_cifar10_output/checkpoint-7971/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 02:20:25,865 >> Model weights saved in ../vit_cifar10_output/checkpoint-7971/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 02:20:25,866 >> Image processor saved in ../vit_cifar10_output/checkpoint-7971/preprocessor_config.json\n",
            "[INFO|trainer.py:2689] 2025-10-02 02:20:28,723 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 4691.4574, 'train_samples_per_second': 27.177, 'train_steps_per_second': 1.699, 'train_loss': 0.363200955192921, 'epoch': 3.0}\n",
            "100% 7971/7971 [1:17:50<00:00,  1.71it/s]\n",
            "[INFO|trainer.py:4133] 2025-10-02 02:20:28,729 >> Saving model checkpoint to ../vit_cifar10_output\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 02:20:28,732 >> Configuration saved in ../vit_cifar10_output/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 02:20:29,785 >> Model weights saved in ../vit_cifar10_output/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 02:20:29,786 >> Image processor saved in ../vit_cifar10_output/preprocessor_config.json\n",
            "***** train metrics *****\n",
            "  epoch                    =          3.0\n",
            "  total_flos               = 9202339782GF\n",
            "  train_loss               =       0.3632\n",
            "  train_runtime            =   1:18:11.45\n",
            "  train_samples_per_second =       27.177\n",
            "  train_steps_per_second   =        1.699\n",
            "[INFO|trainer.py:4465] 2025-10-02 02:20:29,793 >> \n",
            "***** Running Evaluation *****\n",
            "[INFO|trainer.py:4467] 2025-10-02 02:20:29,793 >>   Num examples = 7500\n",
            "[INFO|trainer.py:4470] 2025-10-02 02:20:29,793 >>   Batch size = 8\n",
            "100% 938/938 [01:26<00:00, 10.82it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        3.0\n",
            "  eval_accuracy           =     0.9895\n",
            "  eval_loss               =     0.0533\n",
            "  eval_runtime            = 0:01:26.90\n",
            "  eval_samples_per_second =     86.303\n",
            "  eval_steps_per_second   =     10.794\n",
            "[INFO|modelcard.py:445] 2025-10-02 02:21:56,844 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Image Classification', 'type': 'image-classification'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.9894666666666667}]}\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/transformers/wandb/offline-run-20251002_010235-ujjqqy2c\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20251002_010235-ujjqqy2c/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Lệnh này đảm bảo bạn quay lại thư mục gốc (/content)\n",
        "# để truy cập thư mục output đã được tạo ở cấp độ này\n",
        "try:\n",
        "    os.chdir(\"/content\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Không thể chuyển về thư mục gốc. Vẫn tiếp tục thử đọc file.\")\n",
        "\n",
        "output_dir = \"vit_cifar10_output\"\n",
        "eval_results_path = os.path.join(output_dir, \"eval_results.json\")\n",
        "\n",
        "print(\"\\n--- BẮT ĐẦU THU THẬP KẾT QUẢ CUỐI CÙNG ---\")\n",
        "\n",
        "try:\n",
        "    with open(eval_results_path, 'r') as f:\n",
        "        results = json.load(f)\n",
        "\n",
        "    print(\"\\n--- KẾT QUẢ ĐÁNH GIÁ CUỐI CÙNG CỦA MÔ PHỎNG (ViT) ---\")\n",
        "    for key, value in results.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "    print(\"\\n[THÀNH CÔNG] Chỉ số 'eval_accuracy' là kết quả bạn cần nộp.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Lỗi: Không tìm thấy tệp '{eval_results_path}'. File đã không được lưu đúng cách.\")\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"Lỗi: Tệp '{eval_results_path}' bị hỏng hoặc trống.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rmE3LFmvCKd",
        "outputId": "e0ed1532-a7f1-4e96-a992-3131c6659203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- BẮT ĐẦU THU THẬP KẾT QUẢ CUỐI CÙNG ---\n",
            "\n",
            "--- KẾT QUẢ ĐÁNH GIÁ CUỐI CÙNG CỦA MÔ PHỎNG (ViT) ---\n",
            "epoch: 3.0\n",
            "eval_accuracy: 0.9894666666666667\n",
            "eval_loss: 0.05329902470111847\n",
            "eval_runtime: 86.903\n",
            "eval_samples_per_second: 86.303\n",
            "eval_steps_per_second: 10.794\n",
            "\n",
            "[THÀNH CÔNG] Chỉ số 'eval_accuracy' là kết quả bạn cần nộp.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Đảm bảo đang ở thư mục gốc /content\n",
        "try:\n",
        "    os.chdir(\"/content\")\n",
        "except FileNotFoundError:\n",
        "    pass\n",
        "\n",
        "output_dir = \"vit_cifar10_output\"\n",
        "history_path = os.path.join(output_dir, \"trainer_state.json\")\n",
        "\n",
        "print(\"--- Đang đọc dữ liệu huấn luyện để vẽ biểu đồ (Đã sửa lỗi trục Y) ---\")\n",
        "\n",
        "try:\n",
        "    with open(history_path, 'r') as f:\n",
        "        trainer_state = json.load(f)\n",
        "\n",
        "    # Trích xuất dữ liệu\n",
        "    log_history = trainer_state.get('log_history', [])\n",
        "    train_loss = [log['loss'] for log in log_history if 'loss' in log]\n",
        "    eval_loss = [log['eval_loss'] for log in log_history if 'eval_loss' in log]\n",
        "    eval_accuracy = [log['eval_accuracy'] for log in log_history if 'eval_accuracy' in log]\n",
        "    train_steps = [log['step'] for log in log_history if 'loss' in log]\n",
        "    eval_steps = [log['step'] for log in log_history if 'eval_loss' in log]\n",
        "\n",
        "    # Vẽ Biểu đồ\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Biểu đồ 1: Loss (Không thay đổi)\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_steps, train_loss, label='Training Loss')\n",
        "    plt.plot(eval_steps, eval_loss, label='Evaluation Loss')\n",
        "    plt.title('Loss theo Bước (Training vs. Evaluation)')\n",
        "    plt.xlabel('Steps')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Biểu đồ 2: Accuracy (ĐÃ THÊM THAM SỐ TRỤC Y)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(eval_steps, eval_accuracy, label='Evaluation Accuracy', color='green')\n",
        "    plt.title('Độ chính xác (Accuracy) theo Bước')\n",
        "    plt.xlabel('Steps')\n",
        "    plt.ylabel('Accuracy')\n",
        "\n",
        "    # ĐIỀU CHỈNH CHỦ YẾU: Giới hạn trục Y từ 0.9 đến 1.0 (hoặc hơn)\n",
        "    # Vì độ chính xác của bạn là 0.9895, giới hạn này sẽ hiển thị rõ đường biểu diễn\n",
        "    plt.ylim(0.9, 1.0)\n",
        "\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(f\"\\n[THÀNH CÔNG] Biểu đồ Loss/Accuracy đã được hiển thị.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Lỗi: Không thể vẽ biểu đồ. Chi tiết lỗi: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Owx0r528xgl_",
        "outputId": "1ecdeddc-798d-4f0d-fc18-82d8f7e944c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Đang đọc dữ liệu huấn luyện để vẽ biểu đồ (Đã sửa lỗi trục Y) ---\n",
            "Lỗi: Không thể vẽ biểu đồ. Chi tiết lỗi: [Errno 2] No such file or directory: 'vit_cifar10_output/trainer_state.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from PIL import Image\n",
        "from transformers import ViTForImageClassification, ViTImageProcessor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"--- Đang tải mô hình đã huấn luyện và hiển thị ảnh mẫu ---\")\n",
        "\n",
        "# Đường dẫn đến checkpoint cuối cùng của mô hình\n",
        "model_path = os.path.join(\"vit_cifar10_output\", \"checkpoint-7971\")\n",
        "# Tải mô hình và bộ xử lý đã tinh chỉnh\n",
        "processor = ViTImageProcessor.from_pretrained(model_path)\n",
        "model = ViTForImageClassification.from_pretrained(model_path)\n",
        "\n",
        "# Tải dữ liệu CIFAR-10\n",
        "dataset = load_dataset(\"cifar10\", split=\"test\")\n",
        "labels = dataset.features[\"label\"].names\n",
        "\n",
        "def predict_image(image, model, processor, labels):\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_class_idx = logits.argmax(-1).item()\n",
        "    return labels[predicted_class_idx]\n",
        "\n",
        "# Hiển thị 5 ảnh mẫu\n",
        "plt.figure(figsize=(15, 6))\n",
        "print(\"\\n--- Ảnh Mẫu và Dự đoán của Mô hình (Accuracy: 98.95%) ---\")\n",
        "for i in range(5):\n",
        "    sample = dataset[i]\n",
        "    image = sample['img']\n",
        "    true_label = labels[sample['label']]\n",
        "    predicted_label = predict_image(image, model, processor, labels)\n",
        "\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    plt.imshow(image)\n",
        "    color = 'green' if predicted_label == true_label else 'red'\n",
        "    plt.title(f\"True: {true_label}\\nPred: {predicted_label}\", color=color)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"[HOÀN TẤT] Bài tập của bạn giờ đã rất đầy đủ với kết quả số, biểu đồ, và hình ảnh minh họa.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "uYYIieuR1GPA",
        "outputId": "a8aa6949-a721-4ed3-ec82-d8431a1a5122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Đang tải mô hình đã huấn luyện và hiển thị ảnh mẫu ---\n",
            "\n",
            "--- Ảnh Mẫu và Dự đoán của Mô hình (Accuracy: 98.95%) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HOÀN TẤT] Bài tập của bạn giờ đã rất đầy đủ với kết quả số, biểu đồ, và hình ảnh minh họa.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import ViTForImageClassification, ViTImageProcessor\n",
        "\n",
        "# 1. Chuyển thư mục để tìm đúng file (chuyển vào 'transformers')\n",
        "try:\n",
        "    os.chdir(\"transformers\")\n",
        "    print(f\"Đã chuyển vào thư mục: {os.getcwd()}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Thư mục 'transformers' không tồn tại. Vui lòng đảm bảo đã clone dự án.\")\n",
        "    exit()\n",
        "\n",
        "output_dir = \"vit_cifar10_output\"\n",
        "# ĐƯỜNG DẪN ĐÃ ĐƯỢC ĐỊNH NGHĨA CHÍNH XÁC TỪ TRONG THƯ MỤC 'transformers'\n",
        "history_path = os.path.join(output_dir, \"trainer_state.json\")\n",
        "\n",
        "# --- PHẦN 1: VẼ BIỂU ĐỒ (Sửa lỗi hiển thị trục Y và đường dẫn) ---\n",
        "print(\"\\n--- 1. BẮT ĐẦU VẼ BIỂU ĐỒ (Loss & Accuracy) ---\")\n",
        "try:\n",
        "    with open(history_path, 'r') as f:\n",
        "        trainer_state = json.load(f)\n",
        "\n",
        "    log_history = trainer_state.get('log_history', [])\n",
        "    train_loss = [log['loss'] for log in log_history if 'loss' in log]\n",
        "    eval_loss = [log['eval_loss'] for log in log_history if 'eval_loss' in log]\n",
        "    eval_accuracy = [log['eval_accuracy'] for log in log_history if 'eval_accuracy' in log]\n",
        "    train_steps = [log['step'] for log in log_history if 'loss' in log]\n",
        "    eval_steps = [log['step'] for log in log_history if 'eval_loss' in log]\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Biểu đồ 1: Loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_steps, train_loss, label='Training Loss')\n",
        "    plt.plot(eval_steps, eval_loss, label='Evaluation Loss')\n",
        "    plt.title('Loss theo Bước')\n",
        "    plt.xlabel('Steps')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Biểu đồ 2: Accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(eval_steps, eval_accuracy, label='Evaluation Accuracy', color='green')\n",
        "    plt.title('Độ chính xác (Accuracy) theo Bước')\n",
        "    plt.xlabel('Steps')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.ylim(0.9, 1.0) # ĐIỀU CHỈNH TRỤC Y ĐỂ HIỂN THỊ ĐƯỜNG BIỂU DIỄN RÕ RÀNG\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(f\"[THÀNH CÔNG] Biểu đồ Loss/Accuracy đã được hiển thị.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"[LỖI] Không thể vẽ biểu đồ. Đảm bảo file tồn tại: {e}\")\n",
        "\n",
        "# --- PHẦN 2: HIỂN THỊ HÌNH ẢNH MẪU VÀ DỰ ĐOÁN ---\n",
        "print(\"\\n--- 2. HIỂN THỊ ẢNH MẪU VÀ DỰ ĐOÁN ---\")\n",
        "\n",
        "try:\n",
        "    # Đường dẫn đến checkpoint cuối cùng (từ thư mục 'transformers')\n",
        "    model_path = os.path.join(output_dir, \"checkpoint-7971\")\n",
        "    processor = ViTImageProcessor.from_pretrained(model_path)\n",
        "    model = ViTForImageClassification.from_pretrained(model_path)\n",
        "    dataset = load_dataset(\"cifar10\", split=\"test\")\n",
        "    labels = dataset.features[\"label\"].names\n",
        "\n",
        "    def predict_image(image):\n",
        "        inputs = processor(images=image, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        predicted_class_idx = outputs.logits.argmax(-1).item()\n",
        "        return labels[predicted_class_idx]\n",
        "\n",
        "    plt.figure(figsize=(15, 4))\n",
        "    for i in range(5):\n",
        "        sample = dataset[i]\n",
        "        image = sample['img']\n",
        "        true_label = labels[sample['label']]\n",
        "        predicted_label = predict_image(image)\n",
        "\n",
        "        plt.subplot(1, 5, i + 1)\n",
        "        plt.imshow(image)\n",
        "        color = 'green' if predicted_label == true_label else 'red'\n",
        "        plt.title(f\"True: {true_label}\\nPred: {predicted_label}\", fontsize=8, color=color)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(\"[THÀNH CÔNG] Đã hiển thị hình ảnh mẫu. Bài tập hoàn thành.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"[LỖI] Không thể hiển thị ảnh mẫu. Chi tiết lỗi: {e}\")\n",
        "\n",
        "# Quay lại thư mục gốc\n",
        "os.chdir(\"../\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AfYO8M7-P1d",
        "outputId": "57af6d82-f3f5-44d3-b1b1-605d1805e84e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thư mục 'transformers' không tồn tại. Vui lòng đảm bảo đã clone dự án.\n",
            "\n",
            "--- 1. BẮT ĐẦU VẼ BIỂU ĐỒ (Loss & Accuracy) ---\n",
            "[LỖI] Không thể vẽ biểu đồ. Đảm bảo file tồn tại: [Errno 2] No such file or directory: 'vit_cifar10_output/trainer_state.json'\n",
            "\n",
            "--- 2. HIỂN THỊ ẢNH MẪU VÀ DỰ ĐOÁN ---\n",
            "[LỖI] Không thể hiển thị ảnh mẫu. Chi tiết lỗi: vit_cifar10_output/checkpoint-7971 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
            "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Đảm bảo bạn đang ở thư mục gốc /content\n",
        "try:\n",
        "    os.chdir(\"/content\")\n",
        "except FileNotFoundError:\n",
        "    pass\n",
        "\n",
        "# Chạy lại script huấn luyện để tạo lại thư mục vit_cifar10_output\n",
        "print(\"\\n--- 1. BẮT ĐẦU CHẠY LẠI MÔ PHỎNG VIT ĐỂ TẠO LẠI KẾT QUẢ ---\")\n",
        "# Lệnh này lưu kết quả vào đúng thư mục mà code vẽ biểu đồ sẽ tìm kiếm\n",
        "!python transformers/examples/pytorch/image-classification/run_image_classification.py \\\n",
        "    --model_name_or_path \"google/vit-base-patch16-224-in21k\" \\\n",
        "    --dataset_name \"cifar10\" \\\n",
        "    --output_dir \"./transformers/vit_cifar10_output\" \\\n",
        "    --remove_unused_columns False \\\n",
        "    --do_train --do_eval \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 3 \\\n",
        "    --per_device_train_batch_size 16 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --image_column_name \"img\"\n",
        "print(\"\\n--- HOÀN TẤT CHẠY LẠI HUẤN LUYỆN. BÂY GIỜ CHẠY BƯỚC 2. ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXFbK9FaDAUr",
        "outputId": "8d31bc16-1211-485c-d449-aced73478339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 1. BẮT ĐẦU CHẠY LẠI MÔ PHỎNG VIT ĐỂ TẠO LẠI KẾT QUẢ ---\n",
            "python3: can't open file '/content/transformers/examples/pytorch/image-classification/run_image_classification.py': [Errno 2] No such file or directory\n",
            "\n",
            "--- HOÀN TẤT CHẠY LẠI HUẤN LUYỆN. BÂY GIỜ CHẠY BƯỚC 2. ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Đảm bảo bạn đang ở thư mục gốc /content\n",
        "try:\n",
        "    os.chdir(\"/content\")\n",
        "except FileNotFoundError:\n",
        "    pass\n",
        "\n",
        "# Xóa thư mục cũ (nếu có) và Clone lại dự án\n",
        "print(\"--- 1. Tải lại dự án và cài đặt phụ thuộc ---\")\n",
        "if os.path.exists(\"transformers\"):\n",
        "    !rm -rf transformers\n",
        "!git clone https://github.com/huggingface/transformers.git\n",
        "\n",
        "# Cài đặt lại thư viện\n",
        "os.chdir(\"transformers\")\n",
        "!pip install -e \".[testing]\" --upgrade --force-reinstall\n",
        "os.chdir(\"../\")\n",
        "print(\"--- HOÀN TẤT TẢI LẠI VÀ CÀI ĐẶT ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2rdHMA1DIkS",
        "outputId": "9d4b200f-8081-4321-ee05-e03b07617820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Tải lại dự án và cài đặt phụ thuộc ---\n",
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 347473, done.\u001b[K\n",
            "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 347473 (delta 40), reused 31 (delta 11), pack-reused 347400 (from 2)\u001b[K\n",
            "Receiving objects: 100% (347473/347473), 360.89 MiB | 27.27 MiB/s, done.\n",
            "Resolving deltas: 100% (265159/265159), done.\n",
            "Obtaining file:///content/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting filelock (from transformers==4.57.0.dev0)\n",
            "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting huggingface-hub==1.0.0.rc2 (from transformers==4.57.0.dev0)\n",
            "  Using cached huggingface_hub-1.0.0rc2-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy>=1.17 (from transformers==4.57.0.dev0)\n",
            "  Using cached numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Collecting packaging>=20.0 (from transformers==4.57.0.dev0)\n",
            "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyyaml>=5.1 (from transformers==4.57.0.dev0)\n",
            "  Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers==4.57.0.dev0)\n",
            "  Using cached regex-2025.9.18-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Collecting requests (from transformers==4.57.0.dev0)\n",
            "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers==4.57.0.dev0)\n",
            "  Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers==4.57.0.dev0)\n",
            "  Using cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting tqdm>=4.27 (from transformers==4.57.0.dev0)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub==1.0.0.rc2->transformers==4.57.0.dev0)\n",
            "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from huggingface-hub==1.0.0.rc2->transformers==4.57.0.dev0)\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typer-slim (from huggingface-hub==1.0.0.rc2->transformers==4.57.0.dev0)\n",
            "  Using cached typer_slim-0.19.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub==1.0.0.rc2->transformers==4.57.0.dev0)\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub==1.0.0.rc2->transformers==4.57.0.dev0)\n",
            "  Using cached hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Collecting pytest>=7.2.0 (from transformers==4.57.0.dev0)\n",
            "  Using cached pytest-8.4.2-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting pytest-asyncio (from transformers==4.57.0.dev0)\n",
            "  Using cached pytest_asyncio-1.2.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting pytest-rich (from transformers==4.57.0.dev0)\n",
            "  Using cached pytest_rich-0.2.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting pytest-xdist (from transformers==4.57.0.dev0)\n",
            "  Using cached pytest_xdist-3.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting pytest-order (from transformers==4.57.0.dev0)\n",
            "  Using cached pytest_order-1.3.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting pytest-rerunfailures<16.0 (from transformers==4.57.0.dev0)\n",
            "  Using cached pytest_rerunfailures-15.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting timeout-decorator (from transformers==4.57.0.dev0)\n",
            "  Using cached timeout_decorator-0.5.0-py3-none-any.whl\n",
            "Collecting parameterized>=0.9 (from transformers==4.57.0.dev0)\n",
            "  Using cached parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting psutil (from transformers==4.57.0.dev0)\n",
            "  Using cached psutil-7.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
            "Collecting datasets>=2.15.0 (from transformers==4.57.0.dev0)\n",
            "  Using cached datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting dill<0.3.5 (from transformers==4.57.0.dev0)\n",
            "  Using cached dill-0.3.4-py2.py3-none-any.whl.metadata (9.6 kB)\n",
            "Collecting evaluate>=0.2.0 (from transformers==4.57.0.dev0)\n",
            "  Using cached evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pytest-timeout (from transformers==4.57.0.dev0)\n",
            "  Using cached pytest_timeout-2.4.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting ruff==0.13.1 (from transformers==4.57.0.dev0)\n",
            "  Using cached ruff-0.13.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting rouge-score!=0.0.7,!=0.0.8,!=0.1,!=0.1.1 (from transformers==4.57.0.dev0)\n",
            "  Using cached rouge_score-0.1.2-py3-none-any.whl\n",
            "Collecting nltk<=3.8.1 (from transformers==4.57.0.dev0)\n",
            "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting GitPython<3.1.19 (from transformers==4.57.0.dev0)\n",
            "  Using cached GitPython-3.1.18-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting sacremoses (from transformers==4.57.0.dev0)\n",
            "  Using cached sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting rjieba (from transformers==4.57.0.dev0)\n",
            "  Using cached rjieba-0.1.13-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting beautifulsoup4 (from transformers==4.57.0.dev0)\n",
            "  Using cached beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting tensorboard (from transformers==4.57.0.dev0)\n",
            "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting pydantic>=2 (from transformers==4.57.0.dev0)\n",
            "  Using cached pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
            "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers==4.57.0.dev0)\n",
            "  Using cached sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting sacrebleu<2.0.0,>=1.4.12 (from transformers==4.57.0.dev0)\n",
            "  Using cached sacrebleu-1.5.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting libcst (from transformers==4.57.0.dev0)\n",
            "  Using cached libcst-1.8.5-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (15 kB)\n",
            "Collecting faiss-cpu (from transformers==4.57.0.dev0)\n",
            "  Using cached faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting cookiecutter==1.7.3 (from transformers==4.57.0.dev0)\n",
            "  Using cached cookiecutter-1.7.3-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mistral-common>=1.6.3 (from mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Using cached mistral_common-1.8.5-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting openai>=1.98.0 (from transformers==4.57.0.dev0)\n",
            "  Using cached openai-2.0.1-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting uvicorn (from transformers==4.57.0.dev0)\n",
            "  Using cached uvicorn-0.37.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting fastapi (from transformers==4.57.0.dev0)\n",
            "  Using cached fastapi-0.118.0-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting starlette (from transformers==4.57.0.dev0)\n",
            "  Using cached starlette-0.48.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting torch>=2.2 (from transformers==4.57.0.dev0)\n",
            "  Using cached torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting accelerate>=0.26.0 (from transformers==4.57.0.dev0)\n",
            "  Using cached accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting binaryornot>=0.4.4 (from cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Using cached binaryornot-0.4.4-py2.py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting Jinja2<4.0.0,>=2.7 (from cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting click>=7.0 (from cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting poyo>=0.5.0 (from cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Using cached poyo-0.5.0-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting jinja2-time>=0.2.0 (from cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Using cached jinja2_time-0.2.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-slugify>=4.0.0 (from cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Using cached python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting six>=1.10 (from cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting pyarrow>=21.0.0 (from datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Using cached pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting pandas (from datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Using cached pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "Collecting xxhash (from datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython<3.1.19->transformers==4.57.0.dev0)\n",
            "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting jsonschema>=4.21.1 (from mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting tiktoken>=0.7.0 (from mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Using cached tiktoken-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting pillow>=10.3.0 (from mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Using cached pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Using cached pydantic_extra_types-2.10.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting opencv-python-headless>=4.0.0 (from mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Using cached opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "Collecting joblib (from nltk<=3.8.1->transformers==4.57.0.dev0)\n",
            "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting anyio<5,>=3.5.0 (from openai>=1.98.0->transformers==4.57.0.dev0)\n",
            "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai>=1.98.0->transformers==4.57.0.dev0)\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.98.0->transformers==4.57.0.dev0)\n",
            "  Using cached jiter-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting sniffio (from openai>=1.98.0->transformers==4.57.0.dev0)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic>=2->transformers==4.57.0.dev0)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic>=2->transformers==4.57.0.dev0)\n",
            "  Using cached pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic>=2->transformers==4.57.0.dev0)\n",
            "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting iniconfig>=1 (from pytest>=7.2.0->transformers==4.57.0.dev0)\n",
            "  Using cached iniconfig-2.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting pluggy<2,>=1.5 (from pytest>=7.2.0->transformers==4.57.0.dev0)\n",
            "  Using cached pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting pygments>=2.7.2 (from pytest>=7.2.0->transformers==4.57.0.dev0)\n",
            "  Using cached pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->transformers==4.57.0.dev0)\n",
            "  Using cached charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->transformers==4.57.0.dev0)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.57.0.dev0)\n",
            "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers==4.57.0.dev0)\n",
            "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting absl-py (from rouge-score!=0.0.7,!=0.0.8,!=0.1,!=0.1.1->transformers==4.57.0.dev0)\n",
            "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting portalocker==2.0.0 (from sacrebleu<2.0.0,>=1.4.12->transformers==4.57.0.dev0)\n",
            "  Using cached portalocker-2.0.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting setuptools (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sympy>=1.13.3 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.4.0 (from torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Using cached triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4->transformers==4.57.0.dev0)\n",
            "  Using cached soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting attrs (from pytest-rich->transformers==4.57.0.dev0)\n",
            "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting rich (from pytest-rich->transformers==4.57.0.dev0)\n",
            "  Using cached rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting execnet>=2.1 (from pytest-xdist->transformers==4.57.0.dev0)\n",
            "  Using cached execnet-2.1.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard->transformers==4.57.0.dev0)\n",
            "  Using cached grpcio-1.75.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard->transformers==4.57.0.dev0)\n",
            "  Using cached markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard->transformers==4.57.0.dev0)\n",
            "  Using cached protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->transformers==4.57.0.dev0)\n",
            "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard->transformers==4.57.0.dev0)\n",
            "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting h11>=0.8 (from uvicorn->transformers==4.57.0.dev0)\n",
            "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting chardet>=3.0.2 (from binaryornot>=0.4.4->cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Using cached aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython<3.1.19->transformers==4.57.0.dev0)\n",
            "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->huggingface-hub==1.0.0.rc2->transformers==4.57.0.dev0)\n",
            "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting MarkupSafe>=2.0 (from Jinja2<4.0.0,>=2.7->cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Using cached markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting arrow (from jinja2-time>=0.2.0->cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Using cached arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.21.1->mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=4.21.1->mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=4.21.1->mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Using cached rpds_py-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Using cached multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
            "  Using cached multiprocess-0.70.14-py310-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached multiprocess-0.70.13-py310-none-any.whl.metadata (6.8 kB)\n",
            "  Using cached multiprocess-0.70.12.2-py39-none-any.whl.metadata (6.9 kB)\n",
            "Collecting numpy>=1.17 (from transformers==4.57.0.dev0)\n",
            "  Using cached numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral-common>=1.6.3->mistral-common[opencv]>=1.6.3; extra == \"testing\"->transformers==4.57.0.dev0)\n",
            "  Using cached pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting text-unidecode>=1.3 (from python-slugify>=4.0.0->cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Using cached text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.2->transformers==4.57.0.dev0)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->pytest-rich->transformers==4.57.0.dev0)\n",
            "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Using cached frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Using cached multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Using cached propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.15.0->transformers==4.57.0.dev0)\n",
            "  Using cached yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->pytest-rich->transformers==4.57.0.dev0)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow->jinja2-time>=0.2.0->cookiecutter==1.7.3->transformers==4.57.0.dev0)\n",
            "  Using cached types_python_dateutil-2.9.0.20250822-py3-none-any.whl.metadata (1.8 kB)\n",
            "Using cached huggingface_hub-1.0.0rc2-py3-none-any.whl (528 kB)\n",
            "Using cached cookiecutter-1.7.3-py2.py3-none-any.whl (34 kB)\n",
            "Using cached ruff-0.13.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n",
            "Using cached accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
            "Using cached datasets-4.1.1-py3-none-any.whl (503 kB)\n",
            "Using cached dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
            "Using cached evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "Using cached GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "Using cached mistral_common-1.8.5-py3-none-any.whl (6.5 MB)\n",
            "Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "Using cached openai-2.0.1-py3-none-any.whl (956 kB)\n",
            "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Using cached parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Using cached pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
            "Using cached pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "Using cached pytest-8.4.2-py3-none-any.whl (365 kB)\n",
            "Using cached pytest_rerunfailures-15.1-py3-none-any.whl (13 kB)\n",
            "Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
            "Using cached regex-2025.9.18-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (802 kB)\n",
            "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Using cached sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n",
            "Using cached portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
            "Using cached sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "Using cached torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (887.9 MB)\n",
            "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Using cached triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n",
            "Using cached faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "Using cached fastapi-0.118.0-py3-none-any.whl (97 kB)\n",
            "Using cached starlette-0.48.0-py3-none-any.whl (73 kB)\n",
            "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Using cached libcst-1.8.5-cp312-cp312-manylinux_2_28_x86_64.whl (2.3 MB)\n",
            "Using cached psutil-7.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (291 kB)\n",
            "Using cached pytest_asyncio-1.2.0-py3-none-any.whl (15 kB)\n",
            "Using cached pytest_order-1.3.0-py3-none-any.whl (14 kB)\n",
            "Using cached pytest_rich-0.2.0-py3-none-any.whl (11 kB)\n",
            "Using cached pytest_timeout-2.4.0-py3-none-any.whl (14 kB)\n",
            "Using cached pytest_xdist-3.8.0-py3-none-any.whl (46 kB)\n",
            "Using cached rjieba-0.1.13-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "Using cached sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
            "Using cached uvicorn-0.37.0-py3-none-any.whl (67 kB)\n",
            "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
            "Using cached binaryornot-0.4.4-py2.py3-none-any.whl (9.0 kB)\n",
            "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "Using cached charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
            "Using cached click-8.3.0-py3-none-any.whl (107 kB)\n",
            "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Using cached execnet-2.1.1-py3-none-any.whl (40 kB)\n",
            "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
            "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
            "Using cached grpcio-1.75.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.4 MB)\n",
            "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Using cached hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached iniconfig-2.1.0-py3-none-any.whl (6.0 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached jinja2_time-0.2.0-py2.py3-none-any.whl (6.4 kB)\n",
            "Using cached jiter-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (347 kB)\n",
            "Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
            "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Using cached markdown-3.9-py3-none-any.whl (107 kB)\n",
            "Using cached multiprocess-0.70.12.2-py39-none-any.whl (128 kB)\n",
            "Using cached opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)\n",
            "Using cached numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
            "Using cached pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "Using cached pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
            "Using cached poyo-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Using cached protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
            "Using cached pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
            "Using cached pydantic_extra_types-2.10.5-py3-none-any.whl (38 kB)\n",
            "Using cached pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
            "Using cached python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
            "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Using cached soupsieve-2.8-py3-none-any.whl (36 kB)\n",
            "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "Using cached tiktoken-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "Using cached pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "Using cached rich-14.1.0-py3-none-any.whl (243 kB)\n",
            "Using cached typer_slim-0.19.2-py3-none-any.whl (46 kB)\n",
            "Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "Using cached aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
            "Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
            "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Using cached pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Using cached rpds_py-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (386 kB)\n",
            "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
            "Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Using cached arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Using cached frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Using cached multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
            "Using cached propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\n",
            "Using cached types_python_dateutil-2.9.0.20250822-py3-none-any.whl (17 kB)\n",
            "Using cached yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building editable for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.57.0.dev0-0.editable-py3-none-any.whl size=14982 sha256=9b712cc1a85ccdeb1766dc01f4d622013907a2f654acd663f0fb68f2475449bc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-iehl8z0o/wheels/5d/95/aa/7bf76982b5186f967ea8b0d48a21290fa6c5c65b1e12ae5460\n",
            "Successfully built transformers\n",
            "Installing collected packages: timeout-decorator, text-unidecode, rjieba, pytz, portalocker, nvidia-cusparselt-cu12, mpmath, xxhash, urllib3, tzdata, typing-extensions, types-python-dateutil, tqdm, tensorboard-data-server, sympy, soupsieve, sniffio, smmap, six, setuptools, sentencepiece, safetensors, sacrebleu, ruff, rpds-py, regex, pyyaml, python-slugify, pygments, pycountry, pyarrow, psutil, protobuf, propcache, poyo, pluggy, pillow, parameterized, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multidict, mdurl, MarkupSafe, markdown, joblib, jiter, iniconfig, idna, hf-xet, h11, fsspec, frozenlist, filelock, execnet, distro, dill, click, charset_normalizer, chardet, certifi, attrs, annotated-types, aiohappyeyeballs, absl-py, yarl, werkzeug, uvicorn, typing-inspection, typer-slim, triton, sacremoses, requests, referencing, python-dateutil, pytest, pydantic-core, opencv-python-headless, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nltk, multiprocess, markdown-it-py, libcst, Jinja2, httpcore, grpcio, gitdb, faiss-cpu, binaryornot, beautifulsoup4, anyio, aiosignal, tiktoken, tensorboard, starlette, rouge-score, rich, pytest-xdist, pytest-timeout, pytest-rerunfailures, pytest-order, pytest-asyncio, pydantic, pandas, nvidia-cusolver-cu12, jsonschema-specifications, httpx, GitPython, arrow, aiohttp, torch, pytest-rich, pydantic-extra-types, openai, jsonschema, jinja2-time, huggingface-hub, fastapi, tokenizers, datasets, cookiecutter, accelerate, transformers, mistral-common, evaluate\n",
            "  Attempting uninstall: timeout-decorator\n",
            "    Found existing installation: timeout-decorator 0.5.0\n",
            "    Uninstalling timeout-decorator-0.5.0:\n",
            "      Successfully uninstalled timeout-decorator-0.5.0\n",
            "  Attempting uninstall: text-unidecode\n",
            "    Found existing installation: text-unidecode 1.3\n",
            "    Uninstalling text-unidecode-1.3:\n",
            "      Successfully uninstalled text-unidecode-1.3\n",
            "  Attempting uninstall: rjieba\n",
            "    Found existing installation: rjieba 0.1.13\n",
            "    Uninstalling rjieba-0.1.13:\n",
            "      Successfully uninstalled rjieba-0.1.13\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: portalocker\n",
            "    Found existing installation: portalocker 2.0.0\n",
            "    Uninstalling portalocker-2.0.0:\n",
            "      Successfully uninstalled portalocker-2.0.0\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: xxhash\n",
            "    Found existing installation: xxhash 3.5.0\n",
            "    Uninstalling xxhash-3.5.0:\n",
            "      Successfully uninstalled xxhash-3.5.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: types-python-dateutil\n",
            "    Found existing installation: types-python-dateutil 2.9.0.20250822\n",
            "    Uninstalling types-python-dateutil-2.9.0.20250822:\n",
            "      Successfully uninstalled types-python-dateutil-2.9.0.20250822\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "  Attempting uninstall: soupsieve\n",
            "    Found existing installation: soupsieve 2.8\n",
            "    Uninstalling soupsieve-2.8:\n",
            "      Successfully uninstalled soupsieve-2.8\n",
            "  Attempting uninstall: sniffio\n",
            "    Found existing installation: sniffio 1.3.1\n",
            "    Uninstalling sniffio-1.3.1:\n",
            "      Successfully uninstalled sniffio-1.3.1\n",
            "  Attempting uninstall: smmap\n",
            "    Found existing installation: smmap 5.0.2\n",
            "    Uninstalling smmap-5.0.2:\n",
            "      Successfully uninstalled smmap-5.0.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 80.9.0\n",
            "    Uninstalling setuptools-80.9.0:\n",
            "      Successfully uninstalled setuptools-80.9.0\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.2.1\n",
            "    Uninstalling sentencepiece-0.2.1:\n",
            "      Successfully uninstalled sentencepiece-0.2.1\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.6.2\n",
            "    Uninstalling safetensors-0.6.2:\n",
            "      Successfully uninstalled safetensors-0.6.2\n",
            "  Attempting uninstall: sacrebleu\n",
            "    Found existing installation: sacrebleu 1.5.1\n",
            "    Uninstalling sacrebleu-1.5.1:\n",
            "      Successfully uninstalled sacrebleu-1.5.1\n",
            "  Attempting uninstall: ruff\n",
            "    Found existing installation: ruff 0.13.1\n",
            "    Uninstalling ruff-0.13.1:\n",
            "      Successfully uninstalled ruff-0.13.1\n",
            "  Attempting uninstall: rpds-py\n",
            "    Found existing installation: rpds-py 0.27.1\n",
            "    Uninstalling rpds-py-0.27.1:\n",
            "      Successfully uninstalled rpds-py-0.27.1\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2025.9.18\n",
            "    Uninstalling regex-2025.9.18:\n",
            "      Successfully uninstalled regex-2025.9.18\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.3\n",
            "    Uninstalling PyYAML-6.0.3:\n",
            "      Successfully uninstalled PyYAML-6.0.3\n",
            "  Attempting uninstall: python-slugify\n",
            "    Found existing installation: python-slugify 8.0.4\n",
            "    Uninstalling python-slugify-8.0.4:\n",
            "      Successfully uninstalled python-slugify-8.0.4\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.19.2\n",
            "    Uninstalling Pygments-2.19.2:\n",
            "      Successfully uninstalled Pygments-2.19.2\n",
            "  Attempting uninstall: pycountry\n",
            "    Found existing installation: pycountry 24.6.1\n",
            "    Uninstalling pycountry-24.6.1:\n",
            "      Successfully uninstalled pycountry-24.6.1\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 21.0.0\n",
            "    Uninstalling pyarrow-21.0.0:\n",
            "      Successfully uninstalled pyarrow-21.0.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 7.1.0\n",
            "    Uninstalling psutil-7.1.0:\n",
            "      Successfully uninstalled psutil-7.1.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 6.32.1\n",
            "    Uninstalling protobuf-6.32.1:\n",
            "      Successfully uninstalled protobuf-6.32.1\n",
            "  Attempting uninstall: propcache\n",
            "    Found existing installation: propcache 0.3.2\n",
            "    Uninstalling propcache-0.3.2:\n",
            "      Successfully uninstalled propcache-0.3.2\n",
            "  Attempting uninstall: poyo\n",
            "    Found existing installation: poyo 0.5.0\n",
            "    Uninstalling poyo-0.5.0:\n",
            "      Successfully uninstalled poyo-0.5.0\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 1.6.0\n",
            "    Uninstalling pluggy-1.6.0:\n",
            "      Successfully uninstalled pluggy-1.6.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: parameterized\n",
            "    Found existing installation: parameterized 0.9.0\n",
            "    Uninstalling parameterized-0.9.0:\n",
            "      Successfully uninstalled parameterized-0.9.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.8.90\n",
            "    Uninstalling nvidia-nvtx-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
            "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.13.1.3\n",
            "    Uninstalling nvidia-cufile-cu12-1.13.1.3:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.13.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.6\n",
            "    Uninstalling numpy-2.2.6:\n",
            "      Successfully uninstalled numpy-2.2.6\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.5\n",
            "    Uninstalling networkx-3.5:\n",
            "      Successfully uninstalled networkx-3.5\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.6.4\n",
            "    Uninstalling multidict-6.6.4:\n",
            "      Successfully uninstalled multidict-6.6.4\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.3\n",
            "    Uninstalling MarkupSafe-3.0.3:\n",
            "      Successfully uninstalled MarkupSafe-3.0.3\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.9\n",
            "    Uninstalling Markdown-3.9:\n",
            "      Successfully uninstalled Markdown-3.9\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.5.2\n",
            "    Uninstalling joblib-1.5.2:\n",
            "      Successfully uninstalled joblib-1.5.2\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.11.0\n",
            "    Uninstalling jiter-0.11.0:\n",
            "      Successfully uninstalled jiter-0.11.0\n",
            "  Attempting uninstall: iniconfig\n",
            "    Found existing installation: iniconfig 2.1.0\n",
            "    Uninstalling iniconfig-2.1.0:\n",
            "      Successfully uninstalled iniconfig-2.1.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: hf-xet\n",
            "    Found existing installation: hf-xet 1.1.10\n",
            "    Uninstalling hf-xet-1.1.10:\n",
            "      Successfully uninstalled hf-xet-1.1.10\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.16.0\n",
            "    Uninstalling h11-0.16.0:\n",
            "      Successfully uninstalled h11-0.16.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.9.0\n",
            "    Uninstalling fsspec-2025.9.0:\n",
            "      Successfully uninstalled fsspec-2025.9.0\n",
            "  Attempting uninstall: frozenlist\n",
            "    Found existing installation: frozenlist 1.7.0\n",
            "    Uninstalling frozenlist-1.7.0:\n",
            "      Successfully uninstalled frozenlist-1.7.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.19.1\n",
            "    Uninstalling filelock-3.19.1:\n",
            "      Successfully uninstalled filelock-3.19.1\n",
            "  Attempting uninstall: execnet\n",
            "    Found existing installation: execnet 2.1.1\n",
            "    Uninstalling execnet-2.1.1:\n",
            "      Successfully uninstalled execnet-2.1.1\n",
            "  Attempting uninstall: distro\n",
            "    Found existing installation: distro 1.9.0\n",
            "    Uninstalling distro-1.9.0:\n",
            "      Successfully uninstalled distro-1.9.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.0\n",
            "    Uninstalling click-8.3.0:\n",
            "      Successfully uninstalled click-8.3.0\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.3\n",
            "    Uninstalling charset-normalizer-3.4.3:\n",
            "      Successfully uninstalled charset-normalizer-3.4.3\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.8.3\n",
            "    Uninstalling certifi-2025.8.3:\n",
            "      Successfully uninstalled certifi-2025.8.3\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.3.0\n",
            "    Uninstalling attrs-25.3.0:\n",
            "      Successfully uninstalled attrs-25.3.0\n",
            "  Attempting uninstall: annotated-types\n",
            "    Found existing installation: annotated-types 0.7.0\n",
            "    Uninstalling annotated-types-0.7.0:\n",
            "      Successfully uninstalled annotated-types-0.7.0\n",
            "  Attempting uninstall: aiohappyeyeballs\n",
            "    Found existing installation: aiohappyeyeballs 2.6.1\n",
            "    Uninstalling aiohappyeyeballs-2.6.1:\n",
            "      Successfully uninstalled aiohappyeyeballs-2.6.1\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 2.3.1\n",
            "    Uninstalling absl-py-2.3.1:\n",
            "      Successfully uninstalled absl-py-2.3.1\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.20.1\n",
            "    Uninstalling yarl-1.20.1:\n",
            "      Successfully uninstalled yarl-1.20.1\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: uvicorn\n",
            "    Found existing installation: uvicorn 0.37.0\n",
            "    Uninstalling uvicorn-0.37.0:\n",
            "      Successfully uninstalled uvicorn-0.37.0\n",
            "  Attempting uninstall: typing-inspection\n",
            "    Found existing installation: typing-inspection 0.4.2\n",
            "    Uninstalling typing-inspection-0.4.2:\n",
            "      Successfully uninstalled typing-inspection-0.4.2\n",
            "  Attempting uninstall: typer-slim\n",
            "    Found existing installation: typer-slim 0.19.2\n",
            "    Uninstalling typer-slim-0.19.2:\n",
            "      Successfully uninstalled typer-slim-0.19.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: sacremoses\n",
            "    Found existing installation: sacremoses 0.1.1\n",
            "    Uninstalling sacremoses-0.1.1:\n",
            "      Successfully uninstalled sacremoses-0.1.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.5\n",
            "    Uninstalling requests-2.32.5:\n",
            "      Successfully uninstalled requests-2.32.5\n",
            "  Attempting uninstall: referencing\n",
            "    Found existing installation: referencing 0.36.2\n",
            "    Uninstalling referencing-0.36.2:\n",
            "      Successfully uninstalled referencing-0.36.2\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 8.4.2\n",
            "    Uninstalling pytest-8.4.2:\n",
            "      Successfully uninstalled pytest-8.4.2\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.12.2\n",
            "    Uninstalling multiprocess-0.70.12.2:\n",
            "      Successfully uninstalled multiprocess-0.70.12.2\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 4.0.0\n",
            "    Uninstalling markdown-it-py-4.0.0:\n",
            "      Successfully uninstalled markdown-it-py-4.0.0\n",
            "  Attempting uninstall: libcst\n",
            "    Found existing installation: libcst 1.8.5\n",
            "    Uninstalling libcst-1.8.5:\n",
            "      Successfully uninstalled libcst-1.8.5\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.9\n",
            "    Uninstalling httpcore-1.0.9:\n",
            "      Successfully uninstalled httpcore-1.0.9\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.75.1\n",
            "    Uninstalling grpcio-1.75.1:\n",
            "      Successfully uninstalled grpcio-1.75.1\n",
            "  Attempting uninstall: gitdb\n",
            "    Found existing installation: gitdb 4.0.12\n",
            "    Uninstalling gitdb-4.0.12:\n",
            "      Successfully uninstalled gitdb-4.0.12\n",
            "  Attempting uninstall: faiss-cpu\n",
            "    Found existing installation: faiss-cpu 1.12.0\n",
            "    Uninstalling faiss-cpu-1.12.0:\n",
            "      Successfully uninstalled faiss-cpu-1.12.0\n",
            "  Attempting uninstall: binaryornot\n",
            "    Found existing installation: binaryornot 0.4.4\n",
            "    Uninstalling binaryornot-0.4.4:\n",
            "      Successfully uninstalled binaryornot-0.4.4\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.14.2\n",
            "    Uninstalling beautifulsoup4-4.14.2:\n",
            "      Successfully uninstalled beautifulsoup4-4.14.2\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 4.11.0\n",
            "    Uninstalling anyio-4.11.0:\n",
            "      Successfully uninstalled anyio-4.11.0\n",
            "  Attempting uninstall: aiosignal\n",
            "    Found existing installation: aiosignal 1.4.0\n",
            "    Uninstalling aiosignal-1.4.0:\n",
            "      Successfully uninstalled aiosignal-1.4.0\n",
            "  Attempting uninstall: tiktoken\n",
            "    Found existing installation: tiktoken 0.11.0\n",
            "    Uninstalling tiktoken-0.11.0:\n",
            "      Successfully uninstalled tiktoken-0.11.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.20.0\n",
            "    Uninstalling tensorboard-2.20.0:\n",
            "      Successfully uninstalled tensorboard-2.20.0\n",
            "  Attempting uninstall: starlette\n",
            "    Found existing installation: starlette 0.48.0\n",
            "    Uninstalling starlette-0.48.0:\n",
            "      Successfully uninstalled starlette-0.48.0\n",
            "  Attempting uninstall: rouge-score\n",
            "    Found existing installation: rouge_score 0.1.2\n",
            "    Uninstalling rouge_score-0.1.2:\n",
            "      Successfully uninstalled rouge_score-0.1.2\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 14.1.0\n",
            "    Uninstalling rich-14.1.0:\n",
            "      Successfully uninstalled rich-14.1.0\n",
            "  Attempting uninstall: pytest-xdist\n",
            "    Found existing installation: pytest-xdist 3.8.0\n",
            "    Uninstalling pytest-xdist-3.8.0:\n",
            "      Successfully uninstalled pytest-xdist-3.8.0\n",
            "  Attempting uninstall: pytest-timeout\n",
            "    Found existing installation: pytest-timeout 2.4.0\n",
            "    Uninstalling pytest-timeout-2.4.0:\n",
            "      Successfully uninstalled pytest-timeout-2.4.0\n",
            "  Attempting uninstall: pytest-rerunfailures\n",
            "    Found existing installation: pytest-rerunfailures 15.1\n",
            "    Uninstalling pytest-rerunfailures-15.1:\n",
            "      Successfully uninstalled pytest-rerunfailures-15.1\n",
            "  Attempting uninstall: pytest-order\n",
            "    Found existing installation: pytest-order 1.3.0\n",
            "    Uninstalling pytest-order-1.3.0:\n",
            "      Successfully uninstalled pytest-order-1.3.0\n",
            "  Attempting uninstall: pytest-asyncio\n",
            "    Found existing installation: pytest-asyncio 1.2.0\n",
            "    Uninstalling pytest-asyncio-1.2.0:\n",
            "      Successfully uninstalled pytest-asyncio-1.2.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.9\n",
            "    Uninstalling pydantic-2.11.9:\n",
            "      Successfully uninstalled pydantic-2.11.9\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.3.3\n",
            "    Uninstalling pandas-2.3.3:\n",
            "      Successfully uninstalled pandas-2.3.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
            "  Attempting uninstall: jsonschema-specifications\n",
            "    Found existing installation: jsonschema-specifications 2025.9.1\n",
            "    Uninstalling jsonschema-specifications-2025.9.1:\n",
            "      Successfully uninstalled jsonschema-specifications-2025.9.1\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: GitPython\n",
            "    Found existing installation: GitPython 3.1.18\n",
            "    Uninstalling GitPython-3.1.18:\n",
            "      Successfully uninstalled GitPython-3.1.18\n",
            "  Attempting uninstall: arrow\n",
            "    Found existing installation: arrow 1.3.0\n",
            "    Uninstalling arrow-1.3.0:\n",
            "      Successfully uninstalled arrow-1.3.0\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.12.15\n",
            "    Uninstalling aiohttp-3.12.15:\n",
            "      Successfully uninstalled aiohttp-3.12.15\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0\n",
            "    Uninstalling torch-2.8.0:\n",
            "      Successfully uninstalled torch-2.8.0\n",
            "  Attempting uninstall: pytest-rich\n",
            "    Found existing installation: pytest-rich 0.2.0\n",
            "    Uninstalling pytest-rich-0.2.0:\n",
            "      Successfully uninstalled pytest-rich-0.2.0\n",
            "  Attempting uninstall: pydantic-extra-types\n",
            "    Found existing installation: pydantic-extra-types 2.10.5\n",
            "    Uninstalling pydantic-extra-types-2.10.5:\n",
            "      Successfully uninstalled pydantic-extra-types-2.10.5\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 2.0.1\n",
            "    Uninstalling openai-2.0.1:\n",
            "      Successfully uninstalled openai-2.0.1\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.25.1\n",
            "    Uninstalling jsonschema-4.25.1:\n",
            "      Successfully uninstalled jsonschema-4.25.1\n",
            "  Attempting uninstall: jinja2-time\n",
            "    Found existing installation: jinja2-time 0.2.0\n",
            "    Uninstalling jinja2-time-0.2.0:\n",
            "      Successfully uninstalled jinja2-time-0.2.0\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 1.0.0rc2\n",
            "    Uninstalling huggingface-hub-1.0.0rc2:\n",
            "      Successfully uninstalled huggingface-hub-1.0.0rc2\n",
            "  Attempting uninstall: fastapi\n",
            "    Found existing installation: fastapi 0.118.0\n",
            "    Uninstalling fastapi-0.118.0:\n",
            "      Successfully uninstalled fastapi-0.118.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.1.1\n",
            "    Uninstalling datasets-4.1.1:\n",
            "      Successfully uninstalled datasets-4.1.1\n",
            "  Attempting uninstall: cookiecutter\n",
            "    Found existing installation: cookiecutter 1.7.3\n",
            "    Uninstalling cookiecutter-1.7.3:\n",
            "      Successfully uninstalled cookiecutter-1.7.3\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.10.1\n",
            "    Uninstalling accelerate-1.10.1:\n",
            "      Successfully uninstalled accelerate-1.10.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.0.dev0\n",
            "    Uninstalling transformers-4.57.0.dev0:\n",
            "      Successfully uninstalled transformers-4.57.0.dev0\n",
            "  Attempting uninstall: mistral-common\n",
            "    Found existing installation: mistral_common 1.8.5\n",
            "    Uninstalling mistral_common-1.8.5:\n",
            "      Successfully uninstalled mistral_common-1.8.5\n",
            "  Attempting uninstall: evaluate\n",
            "    Found existing installation: evaluate 0.4.6\n",
            "    Uninstalling evaluate-0.4.6:\n",
            "      Successfully uninstalled evaluate-0.4.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.32.1 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.32.1 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\n",
            "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
            "bigframes 2.21.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.32.1 which is incompatible.\n",
            "tensorflow 2.19.0 requires tensorboard~=2.19.0, but you have tensorboard 2.20.0 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "gradio 5.46.0 requires huggingface-hub<1.0,>=0.33.5, but you have huggingface-hub 1.0.0rc2 which is incompatible.\n",
            "textblob 0.19.0 requires nltk>=3.9, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.18 Jinja2-3.1.6 MarkupSafe-3.0.3 absl-py-2.3.1 accelerate-1.10.1 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 annotated-types-0.7.0 anyio-4.11.0 arrow-1.3.0 attrs-25.3.0 beautifulsoup4-4.14.2 binaryornot-0.4.4 certifi-2025.8.3 chardet-5.2.0 charset_normalizer-3.4.3 click-8.3.0 cookiecutter-1.7.3 datasets-4.1.1 dill-0.3.4 distro-1.9.0 evaluate-0.4.6 execnet-2.1.1 faiss-cpu-1.12.0 fastapi-0.118.0 filelock-3.19.1 frozenlist-1.7.0 fsspec-2025.9.0 gitdb-4.0.12 grpcio-1.75.1 h11-0.16.0 hf-xet-1.1.10 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-1.0.0rc2 idna-3.10 iniconfig-2.1.0 jinja2-time-0.2.0 jiter-0.11.0 joblib-1.5.2 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 libcst-1.8.5 markdown-3.9 markdown-it-py-4.0.0 mdurl-0.1.2 mistral-common-1.8.5 mpmath-1.3.0 multidict-6.6.4 multiprocess-0.70.12.2 networkx-3.5 nltk-3.8.1 numpy-2.2.6 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 openai-2.0.1 opencv-python-headless-4.12.0.88 packaging-25.0 pandas-2.3.3 parameterized-0.9.0 pillow-11.3.0 pluggy-1.6.0 portalocker-2.0.0 poyo-0.5.0 propcache-0.3.2 protobuf-6.32.1 psutil-7.1.0 pyarrow-21.0.0 pycountry-24.6.1 pydantic-2.11.9 pydantic-core-2.33.2 pydantic-extra-types-2.10.5 pygments-2.19.2 pytest-8.4.2 pytest-asyncio-1.2.0 pytest-order-1.3.0 pytest-rerunfailures-15.1 pytest-rich-0.2.0 pytest-timeout-2.4.0 pytest-xdist-3.8.0 python-dateutil-2.9.0.post0 python-slugify-8.0.4 pytz-2025.2 pyyaml-6.0.3 referencing-0.36.2 regex-2025.9.18 requests-2.32.5 rich-14.1.0 rjieba-0.1.13 rouge-score-0.1.2 rpds-py-0.27.1 ruff-0.13.1 sacrebleu-1.5.1 sacremoses-0.1.1 safetensors-0.6.2 sentencepiece-0.2.1 setuptools-80.9.0 six-1.17.0 smmap-5.0.2 sniffio-1.3.1 soupsieve-2.8 starlette-0.48.0 sympy-1.14.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 text-unidecode-1.3 tiktoken-0.11.0 timeout-decorator-0.5.0 tokenizers-0.22.1 torch-2.8.0 tqdm-4.67.1 transformers-4.57.0.dev0 triton-3.4.0 typer-slim-0.19.2 types-python-dateutil-2.9.0.20250822 typing-extensions-4.15.0 typing-inspection-0.4.2 tzdata-2025.2 urllib3-2.5.0 uvicorn-0.37.0 werkzeug-3.1.3 xxhash-3.5.0 yarl-1.20.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "_multiprocess",
                  "accelerate",
                  "aiohappyeyeballs",
                  "aiohttp",
                  "aiosignal",
                  "anyio",
                  "attr",
                  "certifi",
                  "chardet",
                  "click",
                  "datasets",
                  "dateutil",
                  "dill",
                  "filelock",
                  "frozenlist",
                  "fsspec",
                  "google",
                  "h11",
                  "httpcore",
                  "httpx",
                  "huggingface_hub",
                  "idna",
                  "jinja2",
                  "joblib",
                  "markupsafe",
                  "mpmath",
                  "multidict",
                  "multiprocess",
                  "numpy",
                  "packaging",
                  "pandas",
                  "propcache",
                  "psutil",
                  "pyarrow",
                  "pytz",
                  "regex",
                  "requests",
                  "rich",
                  "safetensors",
                  "six",
                  "sniffio",
                  "sympy",
                  "tokenizers",
                  "torch",
                  "torchgen",
                  "tqdm",
                  "transformers",
                  "triton",
                  "urllib3",
                  "xxhash",
                  "yarl"
                ]
              },
              "id": "da0d10084c56419a9b0b98e06865bb82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- HOÀN TẤT TẢI LẠI VÀ CÀI ĐẶT ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Đảm bảo bạn đang ở thư mục gốc /content\n",
        "try:\n",
        "    os.chdir(\"/content\")\n",
        "except FileNotFoundError:\n",
        "    pass\n",
        "\n",
        "# Chạy lại script huấn luyện để tạo lại thư mục vit_cifar10_output\n",
        "print(\"\\n--- 2. BẮT ĐẦU CHẠY LẠI MÔ PHỎNG VIT ĐỂ TẠO LẠI KẾT QUẢ ---\")\n",
        "!python transformers/examples/pytorch/image-classification/run_image_classification.py \\\n",
        "    --model_name_or_path \"google/vit-base-patch16-224-in21k\" \\\n",
        "    --dataset_name \"cifar10\" \\\n",
        "    --output_dir \"./transformers/vit_cifar10_output\" \\\n",
        "    --remove_unused_columns False \\\n",
        "    --do_train --do_eval \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 3 \\\n",
        "    --per_device_train_batch_size 16 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --image_column_name \"img\"\n",
        "print(\"\\n--- HOÀN TẤT CHẠY LẠI HUẤN LUYỆN. BÂY GIỜ CHẠY BƯỚC 3. ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r45Sx_epEZ9r",
        "outputId": "dd225e7e-7e2c-4479-b76f-8a6d748abf6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 2. BẮT ĐẦU CHẠY LẠI MÔ PHỎNG VIT ĐỂ TẠO LẠI KẾT QUẢ ---\n",
            "WARNING:__main__:Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "INFO:__main__:Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=True,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=IntervalStrategy.NO,\n",
            "eval_use_gather_object=False,\n",
            "fp16=False,\n",
            "fp16_full_eval=False,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=None,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_num_input_tokens_seen=no,\n",
            "include_tokens_per_second=None,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=./transformers/vit_cifar10_output/runs/Oct02_08-37-38_58ebe8393d12,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "num_train_epochs=3.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH_FUSED,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=./transformers/vit_cifar10_output,\n",
            "overwrite_output_dir=True,\n",
            "parallelism_config=None,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=16,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=False,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=None,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_liger_kernel=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "README.md: 5.16kB [00:00, 12.3MB/s]\n",
            "plain_text/train-00000-of-00001.parquet: 100% 120M/120M [00:01<00:00, 95.8MB/s]\n",
            "plain_text/test-00000-of-00001.parquet: 100% 23.9M/23.9M [00:00<00:00, 59.2MB/s]\n",
            "Generating train split: 100% 50000/50000 [00:00<00:00, 96577.57 examples/s]\n",
            "Generating test split: 100% 10000/10000 [00:00<00:00, 140199.89 examples/s]\n",
            "Downloading builder script: 4.20kB [00:00, 13.3MB/s]\n",
            "config.json: 100% 502/502 [00:00<00:00, 3.13MB/s]\n",
            "[INFO|configuration_utils.py:759] 2025-10-02 08:37:45,265 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/b4569560a39a0f1af58e3ddaf17facf20ab919b0/config.json\n",
            "[INFO|configuration_utils.py:833] 2025-10-02 08:37:45,266 >> Model config ViTConfig {\n",
            "  \"architectures\": [\n",
            "    \"ViTModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"encoder_stride\": 16,\n",
            "  \"finetuning_task\": \"image-classification\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"airplane\",\n",
            "    \"1\": \"automobile\",\n",
            "    \"2\": \"bird\",\n",
            "    \"3\": \"cat\",\n",
            "    \"4\": \"deer\",\n",
            "    \"5\": \"dog\",\n",
            "    \"6\": \"frog\",\n",
            "    \"7\": \"horse\",\n",
            "    \"8\": \"ship\",\n",
            "    \"9\": \"truck\"\n",
            "  },\n",
            "  \"image_size\": 224,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"airplane\": \"0\",\n",
            "    \"automobile\": \"1\",\n",
            "    \"bird\": \"2\",\n",
            "    \"cat\": \"3\",\n",
            "    \"deer\": \"4\",\n",
            "    \"dog\": \"5\",\n",
            "    \"frog\": \"6\",\n",
            "    \"horse\": \"7\",\n",
            "    \"ship\": \"8\",\n",
            "    \"truck\": \"9\"\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"model_type\": \"vit\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_channels\": 3,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"patch_size\": 16,\n",
            "  \"pooler_act\": \"tanh\",\n",
            "  \"pooler_output_size\": 768,\n",
            "  \"qkv_bias\": true,\n",
            "  \"transformers_version\": \"4.57.0.dev0\"\n",
            "}\n",
            "\n",
            "model.safetensors: 100% 346M/346M [00:04<00:00, 77.3MB/s]\n",
            "[INFO|modeling_utils.py:1101] 2025-10-02 08:37:50,044 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/b4569560a39a0f1af58e3ddaf17facf20ab919b0/model.safetensors\n",
            "[INFO|modeling_utils.py:5337] 2025-10-02 08:37:50,198 >> Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:5347] 2025-10-02 08:37:50,198 >> Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "preprocessor_config.json: 100% 160/160 [00:00<00:00, 823kB/s]\n",
            "[INFO|image_processing_base.py:383] 2025-10-02 08:37:50,405 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/b4569560a39a0f1af58e3ddaf17facf20ab919b0/preprocessor_config.json\n",
            "[INFO|configuration_utils.py:759] 2025-10-02 08:37:50,508 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/b4569560a39a0f1af58e3ddaf17facf20ab919b0/config.json\n",
            "[INFO|configuration_utils.py:833] 2025-10-02 08:37:50,509 >> Model config ViTConfig {\n",
            "  \"architectures\": [\n",
            "    \"ViTModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"encoder_stride\": 16,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"image_size\": 224,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"model_type\": \"vit\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_channels\": 3,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"patch_size\": 16,\n",
            "  \"pooler_act\": \"tanh\",\n",
            "  \"pooler_output_size\": 768,\n",
            "  \"qkv_bias\": true,\n",
            "  \"transformers_version\": \"4.57.0.dev0\"\n",
            "}\n",
            "\n",
            "[WARNING|image_processing_auto.py:347] 2025-10-02 08:37:50,514 >> Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "[INFO|image_processing_base.py:383] 2025-10-02 08:37:50,711 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224-in21k/snapshots/b4569560a39a0f1af58e3ddaf17facf20ab919b0/preprocessor_config.json\n",
            "[INFO|image_processing_utils.py:248] 2025-10-02 08:37:50,711 >> size should be a dictionary on of the following set of keys: ({'height', 'width'}, {'shortest_edge'}, {'shortest_edge', 'longest_edge'}, {'longest_edge'}, {'max_height', 'max_width'}), got 224. Converted to {'height': 224, 'width': 224}.\n",
            "[INFO|image_processing_base.py:428] 2025-10-02 08:37:50,711 >> Image processor ViTImageProcessor {\n",
            "  \"do_convert_rgb\": null,\n",
            "  \"do_normalize\": true,\n",
            "  \"do_rescale\": true,\n",
            "  \"do_resize\": true,\n",
            "  \"image_mean\": [\n",
            "    0.5,\n",
            "    0.5,\n",
            "    0.5\n",
            "  ],\n",
            "  \"image_processor_type\": \"ViTImageProcessor\",\n",
            "  \"image_std\": [\n",
            "    0.5,\n",
            "    0.5,\n",
            "    0.5\n",
            "  ],\n",
            "  \"resample\": 2,\n",
            "  \"rescale_factor\": 0.00392156862745098,\n",
            "  \"size\": {\n",
            "    \"height\": 224,\n",
            "    \"width\": 224\n",
            "  }\n",
            "}\n",
            "\n",
            "2025-10-02 08:37:51.332818: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759394271.378883    7849 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759394271.386828    7849 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759394271.405725    7849 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759394271.405757    7849 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759394271.405762    7849 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759394271.405765    7849 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-02 08:37:51.411212: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "[INFO|trainer.py:2405] 2025-10-02 08:37:55,845 >> ***** Running training *****\n",
            "[INFO|trainer.py:2406] 2025-10-02 08:37:55,846 >>   Num examples = 42,500\n",
            "[INFO|trainer.py:2407] 2025-10-02 08:37:55,846 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:2408] 2025-10-02 08:37:55,846 >>   Instantaneous batch size per device = 16\n",
            "[INFO|trainer.py:2411] 2025-10-02 08:37:55,846 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:2412] 2025-10-02 08:37:55,846 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:2413] 2025-10-02 08:37:55,846 >>   Total optimization steps = 7,971\n",
            "[INFO|trainer.py:2414] 2025-10-02 08:37:55,846 >>   Number of trainable parameters = 85,806,346\n",
            "[INFO|integration_utils.py:858] 2025-10-02 08:37:55,867 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/offline-run-20251002_083804-no210mzn\u001b[0m\n",
            "{'loss': 1.2859, 'grad_norm': 4.7552409172058105, 'learning_rate': 1.8747961359929748e-05, 'epoch': 0.19}\n",
            "  6% 500/7971 [04:45<1:11:57,  1.73it/s][INFO|trainer.py:4133] 2025-10-02 08:42:52,312 >> Saving model checkpoint to ./transformers/vit_cifar10_output/checkpoint-500\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 08:42:52,315 >> Configuration saved in ./transformers/vit_cifar10_output/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 08:42:57,058 >> Model weights saved in ./transformers/vit_cifar10_output/checkpoint-500/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 08:42:57,059 >> Image processor saved in ./transformers/vit_cifar10_output/checkpoint-500/preprocessor_config.json\n",
            "{'loss': 0.5851, 'grad_norm': 1.9711991548538208, 'learning_rate': 1.749341362438841e-05, 'epoch': 0.38}\n",
            " 13% 1000/7971 [09:46<1:06:49,  1.74it/s][INFO|trainer.py:4133] 2025-10-02 08:47:52,623 >> Saving model checkpoint to ./transformers/vit_cifar10_output/checkpoint-1000\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 08:47:52,626 >> Configuration saved in ./transformers/vit_cifar10_output/checkpoint-1000/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 08:47:56,285 >> Model weights saved in ./transformers/vit_cifar10_output/checkpoint-1000/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 08:47:56,288 >> Image processor saved in ./transformers/vit_cifar10_output/checkpoint-1000/preprocessor_config.json\n",
            "{'loss': 0.448, 'grad_norm': 6.995101451873779, 'learning_rate': 1.6238865888847073e-05, 'epoch': 0.56}\n",
            " 19% 1500/7971 [14:43<1:01:50,  1.74it/s][INFO|trainer.py:4133] 2025-10-02 08:52:50,104 >> Saving model checkpoint to ./transformers/vit_cifar10_output/checkpoint-1500\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 08:52:50,106 >> Configuration saved in ./transformers/vit_cifar10_output/checkpoint-1500/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 08:52:53,130 >> Model weights saved in ./transformers/vit_cifar10_output/checkpoint-1500/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 08:52:53,132 >> Image processor saved in ./transformers/vit_cifar10_output/checkpoint-1500/preprocessor_config.json\n",
            "{'loss': 0.3772, 'grad_norm': 5.686676502227783, 'learning_rate': 1.4984318153305734e-05, 'epoch': 0.75}\n",
            " 25% 2000/7971 [19:44<56:54,  1.75it/s][INFO|trainer.py:4133] 2025-10-02 08:57:51,156 >> Saving model checkpoint to ./transformers/vit_cifar10_output/checkpoint-2000\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 08:57:51,158 >> Configuration saved in ./transformers/vit_cifar10_output/checkpoint-2000/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 08:57:56,587 >> Model weights saved in ./transformers/vit_cifar10_output/checkpoint-2000/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 08:57:56,588 >> Image processor saved in ./transformers/vit_cifar10_output/checkpoint-2000/preprocessor_config.json\n",
            "{'loss': 0.3337, 'grad_norm': 4.93037223815918, 'learning_rate': 1.3729770417764396e-05, 'epoch': 0.94}\n",
            " 31% 2500/7971 [24:51<52:54,  1.72it/s][INFO|trainer.py:4133] 2025-10-02 09:02:57,842 >> Saving model checkpoint to ./transformers/vit_cifar10_output/checkpoint-2500\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 09:02:57,845 >> Configuration saved in ./transformers/vit_cifar10_output/checkpoint-2500/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 09:03:04,130 >> Model weights saved in ./transformers/vit_cifar10_output/checkpoint-2500/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 09:03:04,131 >> Image processor saved in ./transformers/vit_cifar10_output/checkpoint-2500/preprocessor_config.json\n",
            "{'loss': 0.307, 'grad_norm': 0.19863839447498322, 'learning_rate': 1.247522268222306e-05, 'epoch': 1.13}\n",
            " 38% 3000/7971 [30:01<47:05,  1.76it/s][INFO|trainer.py:4133] 2025-10-02 09:08:07,923 >> Saving model checkpoint to ./transformers/vit_cifar10_output/checkpoint-3000\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 09:08:07,925 >> Configuration saved in ./transformers/vit_cifar10_output/checkpoint-3000/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 09:08:15,952 >> Model weights saved in ./transformers/vit_cifar10_output/checkpoint-3000/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 09:08:15,953 >> Image processor saved in ./transformers/vit_cifar10_output/checkpoint-3000/preprocessor_config.json\n",
            "{'loss': 0.2888, 'grad_norm': 8.653573989868164, 'learning_rate': 1.1220674946681723e-05, 'epoch': 1.32}\n",
            " 44% 3500/7971 [35:04<42:44,  1.74it/s][INFO|trainer.py:4133] 2025-10-02 09:13:10,609 >> Saving model checkpoint to ./transformers/vit_cifar10_output/checkpoint-3500\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 09:13:10,611 >> Configuration saved in ./transformers/vit_cifar10_output/checkpoint-3500/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 09:13:16,944 >> Model weights saved in ./transformers/vit_cifar10_output/checkpoint-3500/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 09:13:16,946 >> Image processor saved in ./transformers/vit_cifar10_output/checkpoint-3500/preprocessor_config.json\n",
            "{'loss': 0.2834, 'grad_norm': 0.7812482118606567, 'learning_rate': 9.966127211140385e-06, 'epoch': 1.51}\n",
            " 50% 4000/7971 [40:07<37:52,  1.75it/s][INFO|trainer.py:4133] 2025-10-02 09:18:14,040 >> Saving model checkpoint to ./transformers/vit_cifar10_output/checkpoint-4000\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 09:18:14,042 >> Configuration saved in ./transformers/vit_cifar10_output/checkpoint-4000/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 09:18:19,846 >> Model weights saved in ./transformers/vit_cifar10_output/checkpoint-4000/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 09:18:19,849 >> Image processor saved in ./transformers/vit_cifar10_output/checkpoint-4000/preprocessor_config.json\n",
            "{'loss': 0.2705, 'grad_norm': 6.8095316886901855, 'learning_rate': 8.711579475599046e-06, 'epoch': 1.69}\n",
            " 56% 4500/7971 [45:08<33:05,  1.75it/s][INFO|trainer.py:4133] 2025-10-02 09:23:14,607 >> Saving model checkpoint to ./transformers/vit_cifar10_output/checkpoint-4500\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 09:23:14,610 >> Configuration saved in ./transformers/vit_cifar10_output/checkpoint-4500/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 09:23:15,688 >> Model weights saved in ./transformers/vit_cifar10_output/checkpoint-4500/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 09:23:15,690 >> Image processor saved in ./transformers/vit_cifar10_output/checkpoint-4500/preprocessor_config.json\n",
            "{'loss': 0.2666, 'grad_norm': 10.183891296386719, 'learning_rate': 7.4570317400577095e-06, 'epoch': 1.88}\n",
            " 63% 5000/7971 [50:00<28:25,  1.74it/s][INFO|trainer.py:4133] 2025-10-02 09:28:06,998 >> Saving model checkpoint to ./transformers/vit_cifar10_output/checkpoint-5000\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 09:28:07,001 >> Configuration saved in ./transformers/vit_cifar10_output/checkpoint-5000/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 09:28:13,895 >> Model weights saved in ./transformers/vit_cifar10_output/checkpoint-5000/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 09:28:13,897 >> Image processor saved in ./transformers/vit_cifar10_output/checkpoint-5000/preprocessor_config.json\n",
            "{'loss': 0.2457, 'grad_norm': 9.156722068786621, 'learning_rate': 6.202484004516373e-06, 'epoch': 2.07}\n",
            " 69% 5500/7971 [54:58<23:46,  1.73it/s][INFO|trainer.py:4133] 2025-10-02 09:33:04,694 >> Saving model checkpoint to ./transformers/vit_cifar10_output/checkpoint-5500\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 09:33:04,696 >> Configuration saved in ./transformers/vit_cifar10_output/checkpoint-5500/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 09:33:05,850 >> Model weights saved in ./transformers/vit_cifar10_output/checkpoint-5500/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 09:33:05,851 >> Image processor saved in ./transformers/vit_cifar10_output/checkpoint-5500/preprocessor_config.json\n",
            "{'loss': 0.2289, 'grad_norm': 5.947455406188965, 'learning_rate': 4.947936268975035e-06, 'epoch': 2.26}\n",
            " 75% 6000/7971 [59:50<18:50,  1.74it/s][INFO|trainer.py:4133] 2025-10-02 09:37:56,540 >> Saving model checkpoint to ./transformers/vit_cifar10_output/checkpoint-6000\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 09:37:56,543 >> Configuration saved in ./transformers/vit_cifar10_output/checkpoint-6000/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 09:38:02,580 >> Model weights saved in ./transformers/vit_cifar10_output/checkpoint-6000/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 09:38:02,582 >> Image processor saved in ./transformers/vit_cifar10_output/checkpoint-6000/preprocessor_config.json\n",
            "{'loss': 0.2208, 'grad_norm': 1.73615300655365, 'learning_rate': 3.6933885334336973e-06, 'epoch': 2.45}\n",
            " 82% 6500/7971 [1:04:49<14:07,  1.74it/s][INFO|trainer.py:4133] 2025-10-02 09:42:55,378 >> Saving model checkpoint to ./transformers/vit_cifar10_output/checkpoint-6500\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 09:42:55,380 >> Configuration saved in ./transformers/vit_cifar10_output/checkpoint-6500/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 09:43:01,044 >> Model weights saved in ./transformers/vit_cifar10_output/checkpoint-6500/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 09:43:01,047 >> Image processor saved in ./transformers/vit_cifar10_output/checkpoint-6500/preprocessor_config.json\n",
            "{'loss': 0.2296, 'grad_norm': 2.419294595718384, 'learning_rate': 2.43884079789236e-06, 'epoch': 2.63}\n",
            " 88% 7000/7971 [1:09:45<09:13,  1.76it/s][INFO|trainer.py:4133] 2025-10-02 09:47:52,144 >> Saving model checkpoint to ./transformers/vit_cifar10_output/checkpoint-7000\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 09:47:52,146 >> Configuration saved in ./transformers/vit_cifar10_output/checkpoint-7000/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 09:47:57,692 >> Model weights saved in ./transformers/vit_cifar10_output/checkpoint-7000/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 09:47:57,693 >> Image processor saved in ./transformers/vit_cifar10_output/checkpoint-7000/preprocessor_config.json\n",
            "{'loss': 0.2217, 'grad_norm': 3.5330865383148193, 'learning_rate': 1.1842930623510226e-06, 'epoch': 2.82}\n",
            " 94% 7500/7971 [1:14:42<04:30,  1.74it/s][INFO|trainer.py:4133] 2025-10-02 09:52:48,654 >> Saving model checkpoint to ./transformers/vit_cifar10_output/checkpoint-7500\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 09:52:48,657 >> Configuration saved in ./transformers/vit_cifar10_output/checkpoint-7500/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 09:52:54,615 >> Model weights saved in ./transformers/vit_cifar10_output/checkpoint-7500/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 09:52:54,616 >> Image processor saved in ./transformers/vit_cifar10_output/checkpoint-7500/preprocessor_config.json\n",
            "100% 7971/7971 [1:19:21<00:00,  2.23it/s][INFO|trainer.py:4133] 2025-10-02 09:57:28,146 >> Saving model checkpoint to ./transformers/vit_cifar10_output/checkpoint-7971\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 09:57:28,149 >> Configuration saved in ./transformers/vit_cifar10_output/checkpoint-7971/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 09:57:35,245 >> Model weights saved in ./transformers/vit_cifar10_output/checkpoint-7971/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 09:57:35,247 >> Image processor saved in ./transformers/vit_cifar10_output/checkpoint-7971/preprocessor_config.json\n",
            "[INFO|trainer.py:2689] 2025-10-02 09:57:52,277 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 4796.4308, 'train_samples_per_second': 26.582, 'train_steps_per_second': 1.662, 'train_loss': 0.3632364403482154, 'epoch': 3.0}\n",
            "100% 7971/7971 [1:19:45<00:00,  1.67it/s]\n",
            "[INFO|trainer.py:4133] 2025-10-02 09:57:52,283 >> Saving model checkpoint to ./transformers/vit_cifar10_output\n",
            "[INFO|configuration_utils.py:485] 2025-10-02 09:57:52,285 >> Configuration saved in ./transformers/vit_cifar10_output/config.json\n",
            "[INFO|modeling_utils.py:4046] 2025-10-02 09:57:53,675 >> Model weights saved in ./transformers/vit_cifar10_output/model.safetensors\n",
            "[INFO|image_processing_base.py:253] 2025-10-02 09:57:53,677 >> Image processor saved in ./transformers/vit_cifar10_output/preprocessor_config.json\n",
            "***** train metrics *****\n",
            "  epoch                    =          3.0\n",
            "  total_flos               = 9202339782GF\n",
            "  train_loss               =       0.3632\n",
            "  train_runtime            =   1:19:56.43\n",
            "  train_samples_per_second =       26.582\n",
            "  train_steps_per_second   =        1.662\n",
            "[INFO|trainer.py:4465] 2025-10-02 09:57:53,706 >> \n",
            "***** Running Evaluation *****\n",
            "[INFO|trainer.py:4467] 2025-10-02 09:57:53,706 >>   Num examples = 7500\n",
            "[INFO|trainer.py:4470] 2025-10-02 09:57:53,706 >>   Batch size = 8\n",
            "100% 938/938 [01:28<00:00, 10.59it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        3.0\n",
            "  eval_accuracy           =     0.9887\n",
            "  eval_loss               =     0.0543\n",
            "  eval_runtime            = 0:01:28.81\n",
            "  eval_samples_per_second =     84.444\n",
            "  eval_steps_per_second   =     10.561\n",
            "[INFO|modelcard.py:445] 2025-10-02 09:59:22,671 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Image Classification', 'type': 'image-classification'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.9886666666666667}]}\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20251002_083804-no210mzn\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20251002_083804-no210mzn/logs\u001b[0m\n",
            "\n",
            "--- HOÀN TẤT CHẠY LẠI HUẤN LUYỆN. BÂY GIỜ CHẠY BƯỚC 3. ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lVMAKI_riZ5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import ViTForImageClassification, ViTImageProcessor\n",
        "from PIL import Image\n",
        "\n",
        "# 1. ĐỊNH NGHĨA ĐƯỜNG DẪN TUYỆT ĐỐI\n",
        "BASE_DIR = \"/content/transformers/vit_cifar10_output\"\n",
        "HISTORY_PATH = os.path.join(BASE_DIR, \"trainer_state.json\")\n",
        "MODEL_PATH = os.path.join(BASE_DIR, \"checkpoint-7971\")\n",
        "\n",
        "# --- PHẦN 1: VẼ BIỂU ĐỒ ---\n",
        "print(\"\\n--- 1. BẮT ĐẦU VẼ BIỂU ĐỒ ---\")\n",
        "try:\n",
        "    with open(HISTORY_PATH, 'r') as f:\n",
        "        trainer_state = json.load(f)\n",
        "\n",
        "    log_history = trainer_state.get('log_history', [])\n",
        "    train_loss = [log['loss'] for log in log_history if 'loss' in log]\n",
        "    eval_loss = [log['eval_loss'] for log in log_history if 'eval_loss' in log]\n",
        "    eval_accuracy = [log['eval_accuracy'] for log in log_history if 'eval_accuracy' in log]\n",
        "    train_steps = [log['step'] for log in log_history if 'loss' in log]\n",
        "    eval_steps = [log['step'] for log in log_history if 'eval_loss' in log]\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Biểu đồ 1: Loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_steps, train_loss, label='Training Loss'); plt.plot(eval_steps, eval_loss, label='Evaluation Loss')\n",
        "    plt.title('Loss theo Bước'); plt.xlabel('Steps'); plt.ylabel('Loss'); plt.legend(); plt.grid(True)\n",
        "\n",
        "    # Biểu đồ 2: Accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(eval_steps, eval_accuracy, label='Evaluation Accuracy', color='green')\n",
        "    plt.title('Độ chính xác (Accuracy) theo Bước'); plt.xlabel('Steps'); plt.ylabel('Accuracy');\n",
        "    plt.ylim(0.9, 1.0); plt.legend(); plt.grid(True)\n",
        "\n",
        "    plt.tight_layout(); plt.show()\n",
        "    print(\"[THÀNH CÔNG] Biểu đồ đã được hiển thị.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"[LỖI] Không thể vẽ biểu đồ. Chi tiết lỗi: {e}\")\n",
        "\n",
        "\n",
        "# --- PHẦN 2: HIỂN THỊ ẢNH MẪU VÀ DỰ ĐOÁN ---\n",
        "print(\"\\n--- 2. HIỂN THỊ ẢNH MẪU VÀ DỰ ĐOÁN ---\")\n",
        "try:\n",
        "    processor = ViTImageProcessor.from_pretrained(MODEL_PATH)\n",
        "    model = ViTForImageClassification.from_pretrained(MODEL_PATH)\n",
        "    dataset = load_dataset(\"cifar10\", split=\"test\"); labels = dataset.features[\"label\"].names\n",
        "\n",
        "    def predict_image(image):\n",
        "        inputs = processor(images=image, return_tensors=\"pt\");\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        return labels[outputs.logits.argmax(-1).item()]\n",
        "\n",
        "    plt.figure(figsize=(15, 4))\n",
        "    for i in range(5):\n",
        "        sample = dataset[i]; image = sample['img']; true_label = labels[sample['label']]; predicted_label = predict_image(image)\n",
        "        plt.subplot(1, 5, i + 1); plt.imshow(image)\n",
        "        color = 'green' if predicted_label == true_label else 'red'\n",
        "        plt.title(f\"True: {true_label}\\nPred: {predicted_label}\", fontsize=8, color=color); plt.axis('off')\n",
        "\n",
        "    plt.tight_layout(); plt.show()\n",
        "    print(\"[THÀNH CÔNG] Đã hiển thị hình ảnh mẫu. Bài tập hoàn thành.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"[LỖI] Không thể hiển thị ảnh mẫu. Chi tiết lỗi: {e}\")"
      ],
      "metadata": {
        "id": "au4rRyofiaEg",
        "outputId": "a99ef252-24e5-4660-d5a5-8cdcbe4b135f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 1. BẮT ĐẦU VẼ BIỂU ĐỒ ---\n",
            "[LỖI] Không thể vẽ biểu đồ. Chi tiết lỗi: [Errno 2] No such file or directory: '/content/transformers/vit_cifar10_output/trainer_state.json'\n",
            "\n",
            "--- 2. HIỂN THỊ ẢNH MẪU VÀ DỰ ĐOÁN ---\n",
            "[LỖI] Không thể hiển thị ảnh mẫu. Chi tiết lỗi: Can't load image processor for '/content/transformers/vit_cifar10_output/checkpoint-7971'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/content/transformers/vit_cifar10_output/checkpoint-7971' is the correct path to a directory containing a preprocessor_config.json file\n"
          ]
        }
      ]
    }
  ]
}